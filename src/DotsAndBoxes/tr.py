# -*- coding: utf-8 -*-
"""TrainingNoConv.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1zlbTzsXeIub-qltXcEkCWtPCXIkgvUFc

# Init Training

## Imports
"""

import smtplib
import json
import time
import tensorflow as tf
import numpy as np
from tensorflow.keras import datasets, layers, models
from IPython.utils import io
import random
import subprocess
from sklearn.utils import shuffle
import pandas as pd

"""## .Net Loading"""

#! wget -q https://packages.microsoft.com/config/ubuntu/18.04/packages-microsoft-prod.deb;
#! dpkg -i packages-microsoft-prod.deb;
#! apt-get install apt-transport-https;
#! apt-get update;
#! apt-get install aspnetcore-runtime-3.1;
#! apt-get install dotnet-sdk-3.1;

"""# Training"""

# Commented out IPython magic to ensure Python compatibility.
#  drive.mount('/content/gdrive')

path = ""
#   %cd $path

"""## Variables

# Start
"""

# standard settings 
settings = {
  "Uct": 1.41,
  "Ucb": 1,
  "SimulationsP1": 100,
  "SimulationsP2": 100,
  "Seed": 30,
  "MillisecondsP1": 5000,
  "MillisecondsP2": 5000,
  "Bonus": 3,
  "Boxes": 3,
  "NumberOfGames": 50,
  "Agent1Type": 4,
  "Agent1Cnn": 0,
  "Agent2Type": 4,
  "Agent2Cnn": 1,
  "OutputFolder": "Results",
  "OutputFile": "settings-0",
  "OutputId" : "false",
  "Mode": 0
}

# variable
size = settings["NumberOfGames"] * 8 * 24 * 2
size80 = int(size * 0.8)

nset = 0
times = 50
tinitial = 0
ep = 200
saved_model_path_base = "dotsandboxes3"
saved_model_path = "dotsandboxes3"
saved_model_load = "dotsandboxes3"

"""## Looping"""

# looping for training
for t in range(tinitial, times):
    print(f"T-{t}")
    name = f"settings-{nset}"
    filename = f"Settings/{name}.json"
    weights = f"Results/W-{t}.txt"
    # dump of settings file
    with open(filename, "w") as write_file:
        json.dump(settings, write_file)

    # competitive game playing
    print(f"playing dotnet DotsAndBoxes.dll {filename} competitive")
    dproc = subprocess.Popen(f"dotnet DotsAndBoxes.dll {filename}", shell=True)
    dproc.wait()
    
    # 
    finalPath = path + f"Results/{name}-final.txt"
    final = np.loadtxt(finalPath, dtype=int)
    print("defining new settings for training")
    print(f"winner agent {final.item(0)}")    
    settings["Agent1Cnn"] = final.item(0)
    settings["Agent2Cnn"] = final.item(0)
    nset = nset + 1
    name = f"settings-{nset}"
    settings["OutputFile"] = name
    settings["Seed"] = random.randint(1, 500)
    
    # auto training - settings and dump file
    settings["Mode"] = 1
    settings["NumberOfGames"] = int(settings["NumberOfGames"] * 2)
    filename = f"Settings/{name}.json"
    filenameout = f"Results/{name}.out"
    with open(filename, "w") as write_file:
        json.dump(settings, write_file)
   
    # auto training - training mode
    print(f"playing dotnet DotsAndBoxes.dll {filename} training")
    dproc = subprocess.Popen(f"dotnet DotsAndBoxes.dll {filename}", shell=True)
    dproc.wait()

    print("retraining")
    print("loading data")
    gamesPath = path + f"Results/{name}-input.txt"
    valuesPath = path + f"Results/{name}-values.txt"
    policyPath = path + f"Results/{name}-policy.txt"
    finalPath = path + f"Results/{name}-final.txt"

    # loading data for model training
    games = np.loadtxt(gamesPath, dtype=float)
    games = games.reshape(size, 7, 4)
    policy = np.loadtxt(policyPath, dtype=float)
    policy = policy.reshape(size, 28)
    values = np.loadtxt(valuesPath, dtype=float)
    values = values.reshape(size, 1)
    final = np.loadtxt(finalPath, dtype=int)
    
    # shuffle the data
    games, policy, values = shuffle(games, policy, values)

    # training and testing rates
    gamestr, gamestest = games[:size80,:], games[size80:,:]
    policytr, policytest = policy[:size80,:], policy[size80:,:]
    valuestr, valuestest = values[:size80,:], values[size80:,:]

    # winner
    if settings["Agent1Cnn"] == 0:
        saved_model_load = f"{saved_model_path_base}"
    else:
        saved_model_load = f"{saved_model_path_base}_{settings['Agent1Cnn']}"

    # model loading
    print("loading model " + saved_model_load)
    loaded = tf.keras.models.load_model(saved_model_load)

    print("training model " + saved_model_load)
    print(f"files: {gamesPath} {policyPath} {valuesPath}")
    history = loaded.fit(x=gamestr, y=[policytr, valuestr], batch_size=64, epochs=ep, validation_data=(gamestest, [policytest, valuestest]))
    
    # convert the history.history dict to a pandas DataFrame:     
    hist_df = pd.DataFrame(history.history) 
    
    # json file:
    hist_json_file = path + f"Results/history-{t}.json" 
    with open(hist_json_file, mode='w') as f1:
        hist_df.to_json(f1)
    
    # save to csv:  
    hist_csv_file = path + f"Results/history-{t}.csv"
    with open(hist_csv_file, mode='w') as f2:
        hist_df.to_csv(f2)
    
    # saving model
    saved_model_path = f"{saved_model_path_base}_{t + 2}"
    print("saving new model " + saved_model_path)
    tf.keras.models.save_model(loaded, saved_model_path)

    print("defining new settings for competitive")
    print(f"winner agent {final.item(0)}")

    # network cnn version
    finalPath = path + f"Results/{name}-final.txt"
    nset = nset + 1
    name = f"settings-{nset}"
    settings["Agent1Cnn"] = final.item(0)
    if settings["Agent1Cnn"] == 0:
        saved_model_load = f"{saved_model_path_base}"
    else:
        saved_model_load = f"{saved_model_path_base}_{final.item(0)}"

    # saving weights
    obj = []
    for layer in loaded.layers:
        obj = [obj, layer.get_weights()]

    np.savez_compressed(weights, w = np.array(obj, dtype=object)) 

    settings["Agent2Cnn"] = t + 2
    settings["OutputFile"] = name
    settings["Seed"] = random.randint(1, 500)
    # Competitive
    settings["Mode"] = 0
    settings["NumberOfGames"] = int(settings["NumberOfGames"] / 2)

print("End")