{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "cnn.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DSPCom-KmApV"
      },
      "source": [
        "# Convolutional Neural Network (CNN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m7KBpffWzlxH"
      },
      "source": [
        "### Import TensorFlow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iAve6DCL4JH4"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        " \n",
        "from tensorflow.keras import datasets, layers, models\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.preprocessing import normalize\n",
        "from sklearn.utils import shuffle"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cbz9iMotnb7s"
      },
      "source": [
        "TF Version"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PmOwFmM2nXHN"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "foeR_dZgnVFs"
      },
      "source": [
        "TF version"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iwpSJyGDbmOP"
      },
      "source": [
        "**Data - Google Drive - usar acesso ao google drive ou link alternativo abaixo**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hG5mgW83sh9r",
        "outputId": "94845cd3-7cb3-4543-b0a2-6bc8f1d40ab7"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Szmsjivpt_BF",
        "outputId": "2ff431b7-2d09-43fc-c561-e65223306057"
      },
      "source": [
        "path = \"/content/gdrive/My Drive/Projects/DotsAndBoxes/InitialTests/\"\n",
        "%cd $path"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/My Drive/Projects/DotsAndBoxes/InitialTests\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEcn7VN0sxo8"
      },
      "source": [
        "gamesPath = path + \"Results/input.txt\"\n",
        "valuesPath = path + \"Results/values.txt\"\n",
        "policyPath = path + \"Results/policy.txt\"\n",
        "predictPath = path + \"Results/predict.txt\""
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pMm7LZLGQ4zS"
      },
      "source": [
        "**Data - Link Alternativo**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rCsFvWqORRpk"
      },
      "source": [
        "link1 = \"https://drive.google.com/u/1/uc?id=1-4zdSBPX03884ljn40ePX3xmukfmFSXy&export=download\"\n",
        "link2 = \"https://drive.google.com/u/1/uc?id=100ok0_oNduuKNCJe8QRHxdvtplRY5zDo&export=download\"\n",
        "link3 = \"https://drive.google.com/u/1/uc?id=1Dp0hRwAQ74EfI4cOllrKdhVtv-bmuOlf&export=download\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        },
        "id": "yMiLdHr5RG89",
        "outputId": "696a5e2d-0975-465e-c014-16794d6ef7b6"
      },
      "source": [
        "import requests\n",
        "import gdown\n",
        "\n",
        "games = 'input.txt'\n",
        "gdown.download(link1, games, quiet=False) \n",
        "\n",
        "labels = 'input2.txt'\n",
        "gdown.download(link2, labels, quiet=False) \n",
        "\n",
        "predict = 'predict.txt'\n",
        "gdown.download(link3, predict, quiet=False) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/u/1/uc?id=10y3bzzqvWjSjP2naArfi_njvL5_AGLur&export=download\n",
            "To: /content/input.txt\n",
            "4.03MB [00:00, 108MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/u/1/uc?id=1-pIYt46ZfCW4e69Wz641ZyvetQp33HP4&export=download\n",
            "To: /content/input2.txt\n",
            "100%|██████████| 14.7k/14.7k [00:00<00:00, 3.34MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/u/1/uc?id=1Dp0hRwAQ74EfI4cOllrKdhVtv-bmuOlf&export=download\n",
            "To: /content/predict.txt\n",
            "100%|██████████| 19.6k/19.6k [00:00<00:00, 6.28MB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'predict.txt'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdAQ8TZ-beE6"
      },
      "source": [
        "**Dots 3x3**\n",
        "\n",
        "Estados gerados de 300 jogos, com 10 jogadas anteriores, num total de 3000 jogadas\n",
        "(300 x 24) 3000 x 10 x 7 x 4\n",
        "\n",
        "300  Jogos\n",
        "24   Jogadas (total do tabuleiro)\n",
        "3000 Jogadas considerando os 500 jogos\n",
        "10   Estado com historico de 10 tabuleiros anteriores\n",
        "7    linhas + colunas\n",
        "4    elementos por linha \n",
        "\n",
        "Label = Jogos ganhos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bUBCUB7BqeCD"
      },
      "source": [
        "Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgDWAV1atMeD"
      },
      "source": [
        "arr = np.loadtxt(games, dtype=float)\n",
        "arr = arr.reshape(12000, 7, 4)\n",
        "arrtr, arrtest = arr[:10000,:], arr[10000:,:]\n",
        "\n",
        "arr2 = np.loadtxt(labels, dtype=float)\n",
        "arr2 = arr2.reshape(12000, 1)\n",
        "arr2tr, arr2test = arr2[:10000,:], arr2[10000:,:]\n",
        "\n",
        "arr3 = np.loadtxt(labels, dtype=float)\n",
        "arr3 = arr3.reshape(12000, 1)\n",
        "arr3tr, arr3test = arr3[:10000,:], arr3[10000:,:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "voKM8IKA3my-"
      },
      "source": [
        "arr = np.loadtxt(games, dtype=float)\n",
        "arr = arr.reshape(12000, 7, 4)\n",
        "arrtr, arrtest = arr[:10000,:], arr[10000:,:]\n",
        "\n",
        "arr2 = np.loadtxt(labels, dtype=float)\n",
        "arr2 = arr2.reshape(12000, 1)\n",
        "arr2tr, arr2test = arr2[:10000,:], arr2[10000:,:]\n",
        "\n",
        "arr3 = np.loadtxt(labels, dtype=float)\n",
        "arr3 = arr3.reshape(12000, 1)\n",
        "arr3tr, arr3test = arr3[:10000,:], arr3[10000:,:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZpPejyuCy4L6"
      },
      "source": [
        "arr = np.loadtxt(games, dtype=float)\n",
        "arr = arr.reshape(1, 7, 4)\n",
        "arrtr, arrtest = arr[:3072,:], arr[3072:,:]\n",
        " \n",
        "arr2 = np.loadtxt(policy, dtype=float)\n",
        "arr2 = arr2.reshape(3840, 28)\n",
        "arr2tr, arr2test = arr2[:3072,:], arr2[3072:,:]\n",
        " \n",
        "arr3 = np.loadtxt(values, dtype=float)\n",
        "arr3 = arr3.reshape(3840, 1)\n",
        "arr3tr, arr3test = arr3[:3072,:], arr3[3072:,:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltng749ZYKF8"
      },
      "source": [
        "NumberOfGames= 500\n",
        "size = NumberOfGames * 8 * 24\n",
        "size80 = int(size * 0.8)\n",
        "\n",
        "games = np.loadtxt(gamesPath, dtype=float)\n",
        "games = games.reshape(size, 7, 4)\n",
        "policy = np.loadtxt(policyPath, dtype=float)\n",
        "policy = policy.reshape(size, 28)\n",
        "values = np.loadtxt(valuesPath, dtype=float)\n",
        "values = values.reshape(size, 1)\n",
        "\n",
        "games, policy, values = shuffle(games, policy, values)\n",
        "\n",
        "#c = list(zip(games, policy, values))\n",
        "#np.random.shuffle(c)\n",
        "#games, policy, values = list(zip(*c))\n",
        "#games = np.asarray(games)\n",
        "#policy = np.asarray(policy)\n",
        "#values = np.array(values)\n",
        "\n",
        "gamestr, gamestest = games[:size80,:], games[size80:,:]\n",
        "policytr, policytest = policy[:size80,:], policy[size80:,:]\n",
        "valuestr, valuestest = values[:size80,:], values[size80:,:]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "id": "D54CtKkxe0YM",
        "outputId": "e8e8db19-df04-4e0c-ea00-adb10826592c"
      },
      "source": [
        "NumberOfGames= 500\n",
        "size = NumberOfGames * 24\n",
        "size80 = int(size * 0.8)\n",
        "\n",
        "games = np.loadtxt(gamesPath, dtype=float)\n",
        "games = games.reshape(8 * size, 8, 7, 4)\n",
        "policy = np.loadtxt(policyPath, dtype=float)\n",
        "policy = policy.reshape(8 * size, 224)\n",
        "values = np.loadtxt(valuesPath, dtype=float)\n",
        "values = values.reshape(8 * size, 8, 1)\n",
        "\n",
        "games, policy, values = shuffle(games, policy, values)\n",
        "\n",
        "#c = list(zip(games, policy, values))\n",
        "#np.random.shuffle(c)\n",
        "#games, policy, values = list(zip(*c))\n",
        "#games = np.asarray(games)\n",
        "#policy = np.asarray(policy)\n",
        "#values = np.array(values)\n",
        "\n",
        "gamestr, gamestest = games[:size80,:], games[size80:,:]\n",
        "policytr, policytest = policy[:size80,:], policy[size80:,:]\n",
        "valuestr, valuestest = values[:size80,:], values[size80:,:]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-948d74549e0f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mgames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgamesPath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mgames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgames\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mpolicy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpolicyPath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mpolicy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 33600000 into shape (96000,8,7,4)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ZIAqs_QBZc4",
        "outputId": "cd8241ce-6bb1-4b3f-e62e-558f1cdbcc40"
      },
      "source": [
        "policy[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.00000000e+00, 3.79300000e-42, 1.59551990e-27, 0.00000000e+00,\n",
              "       4.07213500e-33, 1.00000000e+00, 0.00000000e+00, 2.32518920e-29,\n",
              "       3.79247130e-32, 5.80846900e-27, 3.97669440e-36, 0.00000000e+00,\n",
              "       0.00000000e+00, 3.88349000e-39, 1.07127925e-33, 3.18301850e-24,\n",
              "       0.00000000e+00, 3.79300000e-42, 0.00000000e+00, 0.00000000e+00,\n",
              "       2.23941630e-27, 1.12331770e-27, 5.35372120e-28, 2.18693000e-30,\n",
              "       3.97669440e-36, 3.70358520e-35, 0.00000000e+00, 0.00000000e+00])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zy9wD2sITfuR",
        "outputId": "5663c12f-655f-44c5-870a-9242ef56de3b"
      },
      "source": [
        "games.size"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5376000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4PdZNaxTin9",
        "outputId": "21f3d852-f44b-43e1-f3ca-8ff06391c2ea"
      },
      "source": [
        "gamestr.size"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4300800"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6iJUCADHUA9R",
        "outputId": "d75fa7f6-a8aa-4ba8-9984-f22f15e3e49e"
      },
      "source": [
        "gamestest.size"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1075200"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4d90ePsEe7jj"
      },
      "source": [
        "# adjust\n",
        "arr3 = arr2[:,28]\n",
        "arr3 = arr3.reshape(size, 1)\n",
        "\n",
        "with np.nditer(arr3, op_flags=['readwrite']) as it:\n",
        "   for x in it:\n",
        "      if x[...] == 0:\n",
        "        x[...] = -1\n",
        "\n",
        "arr3tr, arr3test = arr3[:size80,:], arr3[size80:,:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jSLvuE_Aqf9h"
      },
      "source": [
        "Official"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "id": "0K5PRmg9qcD5",
        "outputId": "eb6b3f19-2e5a-4793-aea4-60ba7f4e1a6b"
      },
      "source": [
        "arr = np.loadtxt(games, dtype=float)\n",
        "arr = arr.reshape(3600, 11, 7, 4)\n",
        "arrtr, arrtest = arr[:3000,:], arr[3000:,:]\n",
        "\n",
        "arr2 = np.loadtxt(labels, dtype=float)\n",
        "arr2 = arr2.reshape(3600, 1)\n",
        "arr2tr, arr2test = arr2[:3000,:], arr2[3000:,:]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-ffd61ae35dbb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3600\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m11\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0marrtr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marrtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3000\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0marr2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 5376000 into shape (3600,11,7,4)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oewp-wYg31t9"
      },
      "source": [
        "### Create the convolutional base"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DnnnpWWebrON"
      },
      "source": [
        "2D\n",
        "Teste"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LW-ycGF3X77D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2cc02358-3fd9-4f4f-988c-55b58a5a16f3"
      },
      "source": [
        "state = layers.Input(shape=(8, 7, 4), name=\"state_8_7_4\")\n",
        "size = 8 * 7 * 4\n",
        "conv_1 = (layers.Activation('relu', name=\"act1\")(layers.BatchNormalization(axis=1, name=\"batch1\")(layers.Conv2D(filters=256, kernel_size=(3, 3), name='conv_1')(state))))\n",
        "conv_2 = (layers.Activation('relu', name=\"act2\")(layers.BatchNormalization(axis=1, name=\"batch2\")(layers.Conv2D(filters=256, kernel_size=(3, 3), name='conv_2')(conv_1))))\n",
        "conv_3 = (layers.Activation('relu', name=\"act3\")(layers.BatchNormalization(axis=1, name=\"batch3\")(layers.Conv2D(filters=256, kernel_size=(3, 3), name='conv_3')(conv_2))))\n",
        "conv_4 = (layers.Activation('relu', name=\"act4\")(layers.BatchNormalization(axis=1, name=\"batch4\")(layers.Conv2D(filters=2, kernel_size=(1, 1), name='conv_4')(conv_3))))\n",
        "flat = layers.Flatten(name=\"flatten\")(conv_4)\n",
        "pi = layers.Dense(size, activation='softmax', name='policy_net')(flat)   \n",
        "v = layers.Dense(1, activation='tanh', name='value_net')(flat)          \n",
        " \n",
        "model = models.Model(inputs=state, outputs=[pi, v], name=\"noConv8x7x4\")\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"noConv8x7x4\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "state_8_7_4 (InputLayer)        [(None, 8, 7, 4)]    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv_1 (Conv2D)                 (None, 6, 5, 256)    9472        state_8_7_4[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch1 (BatchNormalization)     (None, 6, 5, 256)    24          conv_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "act1 (Activation)               (None, 6, 5, 256)    0           batch1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv_2 (Conv2D)                 (None, 4, 3, 256)    590080      act1[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "batch2 (BatchNormalization)     (None, 4, 3, 256)    16          conv_2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "act2 (Activation)               (None, 4, 3, 256)    0           batch2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv_3 (Conv2D)                 (None, 2, 1, 256)    590080      act2[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "batch3 (BatchNormalization)     (None, 2, 1, 256)    8           conv_3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "act3 (Activation)               (None, 2, 1, 256)    0           batch3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv_4 (Conv2D)                 (None, 2, 1, 2)      514         act3[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "batch4 (BatchNormalization)     (None, 2, 1, 2)      8           conv_4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "act4 (Activation)               (None, 2, 1, 2)      0           batch4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 4)            0           act4[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "policy_net (Dense)              (None, 224)          1120        flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "value_net (Dense)               (None, 1)            5           flatten[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 1,191,327\n",
            "Trainable params: 1,191,299\n",
            "Non-trainable params: 28\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_HJ8xJHDYxk"
      },
      "source": [
        "# Experimental sem convolutional"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obeHgiLJzmvm"
      },
      "source": [
        "https://github.com/suragnair/alpha-zero-general/blob/master/dotsandboxes/keras/DotsAndBoxesNNet.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ol5rpIjSPwb",
        "outputId": "ce66d9fc-cd4a-4364-8fc3-dd03022efb59"
      },
      "source": [
        "dropout = 0.3\n",
        "state = layers.Input(shape=(7, 4), name=\"state_7_4\")\n",
        "size = 7 * 4\n",
        "flat = layers.Flatten(name=\"flatten\")(state)\n",
        "s_fc1 = layers.Dropout(dropout, name=\"drop1\")(layers.Activation('relu', name=\"act1\")(layers.BatchNormalization(axis=1, name=\"batch1\")(layers.Dense(1024, name=\"dense1\")(flat))))  # batch_size x 1024\n",
        "s_fc2 = layers.Dropout(dropout, name=\"drop2\")(layers.Activation('relu', name=\"act2\")(layers.BatchNormalization(axis=1, name=\"batch2\")(layers.Dense(1024, name=\"dense2\")(s_fc1))))  # batch_size x 1024\n",
        "s_fc3 = layers.Dropout(dropout, name=\"drop3\")(layers.Activation('relu', name=\"act3\")(layers.BatchNormalization(axis=1, name=\"batch3\")(layers.Dense(1024, name=\"dense3\")(s_fc2))))  # batch_size x 1024\n",
        "s_fc4 = layers.Dropout(dropout, name=\"drop4\")(layers.Activation('relu', name=\"act4\")(layers.BatchNormalization(axis=1, name=\"batch4\")(layers.Dense(512, name=\"dense4\")(s_fc3))))   # batch_size x 1024\n",
        "pi = layers.Dense(size, activation='softmax', name='policy_net')(s_fc4)   # batch_size x self.action_size\n",
        "v = layers.Dense(1, activation='tanh', name='value_net')(s_fc4)           # batch_size x 1\n",
        " \n",
        "model = models.Model(inputs=state, outputs=[pi, v], name=\"noConv7x4\")\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"noConv7x4\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "state_7_4 (InputLayer)          [(None, 7, 4)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 28)           0           state_7_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense1 (Dense)                  (None, 1024)         29696       flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch1 (BatchNormalization)     (None, 1024)         4096        dense1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "act1 (Activation)               (None, 1024)         0           batch1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "drop1 (Dropout)                 (None, 1024)         0           act1[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "dense2 (Dense)                  (None, 1024)         1049600     drop1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch2 (BatchNormalization)     (None, 1024)         4096        dense2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "act2 (Activation)               (None, 1024)         0           batch2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "drop2 (Dropout)                 (None, 1024)         0           act2[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "dense3 (Dense)                  (None, 1024)         1049600     drop2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch3 (BatchNormalization)     (None, 1024)         4096        dense3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "act3 (Activation)               (None, 1024)         0           batch3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "drop3 (Dropout)                 (None, 1024)         0           act3[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "dense4 (Dense)                  (None, 512)          524800      drop3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch4 (BatchNormalization)     (None, 512)          2048        dense4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "act4 (Activation)               (None, 512)          0           batch4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "drop4 (Dropout)                 (None, 512)          0           act4[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "policy_net (Dense)              (None, 28)           14364       drop4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "value_net (Dense)               (None, 1)            513         drop4[0][0]                      \n",
            "==================================================================================================\n",
            "Total params: 2,682,909\n",
            "Trainable params: 2,675,741\n",
            "Non-trainable params: 7,168\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w5s8VZQtWAwY"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "boDcTloAWChD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd9fb221-3481-4f98-da3e-1a871401a2bd"
      },
      "source": [
        "dropout = 0.3\n",
        "state = layers.Input(shape=(7, 4), name=\"state_7_4\")\n",
        "size = 7 * 4\n",
        "flat = layers.Flatten(name=\"flatten\")(state)\n",
        "s_fc1 = layers.Dropout(dropout, name=\"drop1\")(layers.Activation('relu', name=\"act1\")(layers.BatchNormalization(axis=1, name=\"batch1\")(layers.Dense(1024, name=\"dense1\")(flat))))  # batch_size x 1024\n",
        "s_fc2 = layers.Dropout(dropout, name=\"drop2\")(layers.Activation('relu', name=\"act2\")(layers.BatchNormalization(axis=1, name=\"batch2\")(layers.Dense(256, name=\"dense2\")(s_fc1))))  # batch_size x 1024\n",
        "s_fc3 = layers.Dropout(dropout, name=\"drop3\")(layers.Activation('relu', name=\"act3\")(layers.BatchNormalization(axis=1, name=\"batch3\")(layers.Dense(128, name=\"dense3\")(s_fc2))))  # batch_size x 1024\n",
        "pi = layers.Dense(size, activation='softmax', name='policy_net')(s_fc3)   # batch_size x self.action_size\n",
        "v = layers.Dense(1, activation='tanh', name='value_net')(s_fc3)           # batch_size x 1\n",
        " \n",
        "model = models.Model(inputs=state, outputs=[pi, v], name=\"noConv7x4\")\n",
        "model.summary()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"noConv7x4\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "state_7_4 (InputLayer)          [(None, 7, 4)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 28)           0           state_7_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense1 (Dense)                  (None, 1024)         29696       flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch1 (BatchNormalization)     (None, 1024)         4096        dense1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "act1 (Activation)               (None, 1024)         0           batch1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "drop1 (Dropout)                 (None, 1024)         0           act1[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "dense2 (Dense)                  (None, 256)          262400      drop1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch2 (BatchNormalization)     (None, 256)          1024        dense2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "act2 (Activation)               (None, 256)          0           batch2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "drop2 (Dropout)                 (None, 256)          0           act2[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "dense3 (Dense)                  (None, 128)          32896       drop2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch3 (BatchNormalization)     (None, 128)          512         dense3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "act3 (Activation)               (None, 128)          0           batch3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "drop3 (Dropout)                 (None, 128)          0           act3[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "policy_net (Dense)              (None, 28)           3612        drop3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "value_net (Dense)               (None, 1)            129         drop3[0][0]                      \n",
            "==================================================================================================\n",
            "Total params: 334,365\n",
            "Trainable params: 331,549\n",
            "Non-trainable params: 2,816\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJDVRs-sDjQn"
      },
      "source": [
        "# fim experimental"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "t8rCx8NgKlpZ",
        "outputId": "b36e2665-a74d-4bd1-892f-6057b86bccfe"
      },
      "source": [
        "with open('Results/model.json', mode='r') as f33:\n",
        "    loadedModel = tf.keras.models.model_from_json('model.json');"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "JSONDecodeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-0c41f450de84>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Results/model.json'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf33\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mloadedModel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_from_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/saving/model_config.py\u001b[0m in \u001b[0;36mmodel_from_json\u001b[0;34m(json_string, custom_objects)\u001b[0m\n\u001b[1;32m    122\u001b[0m       \u001b[0mA\u001b[0m \u001b[0mKeras\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0minstance\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0muncompiled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m   \"\"\"\n\u001b[0;32m--> 124\u001b[0;31m   \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m   \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeserialize\u001b[0m  \u001b[0;31m# pylint: disable=g-import-not-at-top\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mdeserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/saving/saved_model/json_utils.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(json_string)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_string\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobject_hook\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_decode_helper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    359\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mparse_constant\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m         \u001b[0mkw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'parse_constant'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_constant\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 361\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/lib/python3.7/json/decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \"\"\"\n\u001b[0;32m--> 337\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/json/decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    353\u001b[0m             \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expecting value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P3odqfHP4M67"
      },
      "source": [
        "### Compile and train the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cMYY9b-lP2L9"
      },
      "source": [
        "Utilizei o mean squared error e resultou, mas não sei se tem melhor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzbDaaIkO2v6"
      },
      "source": [
        "opt2 = tf.keras.optimizers.Adam(\n",
        "    learning_rate=0.0001,\n",
        "    name=\"Adam\"\n",
        ")\n",
        " \n",
        "model.compile(optimizer=opt2,\n",
        "              loss=['categorical_crossentropy','mean_squared_error'])\n",
        " \n",
        "history = model.fit(x=gamestr, y=[policytr, valuestr], batch_size=64, epochs=100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nIVZWbc8B0Ov",
        "outputId": "435e8d8e-7465-4683-ebff-9f0765aceac4"
      },
      "source": [
        "opt2 = tf.keras.optimizers.Adam(\n",
        "    learning_rate=0.001,\n",
        "    name=\"Adam\"\n",
        ")\n",
        "\n",
        "#sgd = tf.keras.optimizers.SGD(lr=0.001, momentum=0.90, nesterov=False)\n",
        " \n",
        "model.compile(optimizer=opt2,\n",
        "              loss=['categorical_crossentropy','mean_squared_error'])\n",
        " \n",
        "history = model.fit(x=gamestr, y=[policytr, valuestr], batch_size=64, epochs=400, validation_data=(gamestest, [policytest, valuestest]))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/400\n",
            "1200/1200 [==============================] - 11s 6ms/step - loss: 3.6936 - policy_net_loss: 2.6563 - value_net_loss: 1.0373 - val_loss: 3.2036 - val_policy_net_loss: 2.2799 - val_value_net_loss: 0.9237\n",
            "Epoch 2/400\n",
            "1200/1200 [==============================] - 7s 6ms/step - loss: 3.3283 - policy_net_loss: 2.3883 - value_net_loss: 0.9400 - val_loss: 3.1095 - val_policy_net_loss: 2.1785 - val_value_net_loss: 0.9310\n",
            "Epoch 3/400\n",
            "1200/1200 [==============================] - 7s 6ms/step - loss: 3.2389 - policy_net_loss: 2.3002 - value_net_loss: 0.9387 - val_loss: 3.0400 - val_policy_net_loss: 2.1160 - val_value_net_loss: 0.9240\n",
            "Epoch 4/400\n",
            "1200/1200 [==============================] - 7s 6ms/step - loss: 3.1710 - policy_net_loss: 2.2344 - value_net_loss: 0.9366 - val_loss: 2.9668 - val_policy_net_loss: 2.0474 - val_value_net_loss: 0.9194\n",
            "Epoch 5/400\n",
            "1200/1200 [==============================] - 7s 6ms/step - loss: 3.1306 - policy_net_loss: 2.1956 - value_net_loss: 0.9351 - val_loss: 2.9494 - val_policy_net_loss: 2.0284 - val_value_net_loss: 0.9210\n",
            "Epoch 6/400\n",
            "1200/1200 [==============================] - 7s 6ms/step - loss: 3.0978 - policy_net_loss: 2.1638 - value_net_loss: 0.9340 - val_loss: 2.9203 - val_policy_net_loss: 2.0035 - val_value_net_loss: 0.9168\n",
            "Epoch 7/400\n",
            "1200/1200 [==============================] - 7s 6ms/step - loss: 3.0685 - policy_net_loss: 2.1360 - value_net_loss: 0.9325 - val_loss: 2.8840 - val_policy_net_loss: 1.9662 - val_value_net_loss: 0.9178\n",
            "Epoch 8/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 3.0428 - policy_net_loss: 2.1102 - value_net_loss: 0.9326 - val_loss: 2.8796 - val_policy_net_loss: 1.9633 - val_value_net_loss: 0.9163\n",
            "Epoch 9/400\n",
            "1200/1200 [==============================] - 7s 6ms/step - loss: 3.0162 - policy_net_loss: 2.0860 - value_net_loss: 0.9302 - val_loss: 2.8466 - val_policy_net_loss: 1.9331 - val_value_net_loss: 0.9135\n",
            "Epoch 10/400\n",
            "1200/1200 [==============================] - 7s 6ms/step - loss: 2.9942 - policy_net_loss: 2.0654 - value_net_loss: 0.9288 - val_loss: 2.8410 - val_policy_net_loss: 1.9292 - val_value_net_loss: 0.9118\n",
            "Epoch 11/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.9740 - policy_net_loss: 2.0456 - value_net_loss: 0.9284 - val_loss: 2.8163 - val_policy_net_loss: 1.9045 - val_value_net_loss: 0.9118\n",
            "Epoch 12/400\n",
            "1200/1200 [==============================] - 7s 6ms/step - loss: 2.9612 - policy_net_loss: 2.0328 - value_net_loss: 0.9283 - val_loss: 2.8106 - val_policy_net_loss: 1.9005 - val_value_net_loss: 0.9100\n",
            "Epoch 13/400\n",
            "1200/1200 [==============================] - 7s 6ms/step - loss: 2.9420 - policy_net_loss: 2.0151 - value_net_loss: 0.9269 - val_loss: 2.8035 - val_policy_net_loss: 1.8922 - val_value_net_loss: 0.9113\n",
            "Epoch 14/400\n",
            "1200/1200 [==============================] - 7s 6ms/step - loss: 2.9243 - policy_net_loss: 1.9986 - value_net_loss: 0.9257 - val_loss: 2.7871 - val_policy_net_loss: 1.8781 - val_value_net_loss: 0.9090\n",
            "Epoch 15/400\n",
            "1200/1200 [==============================] - 7s 6ms/step - loss: 2.9126 - policy_net_loss: 1.9886 - value_net_loss: 0.9240 - val_loss: 2.7786 - val_policy_net_loss: 1.8695 - val_value_net_loss: 0.9091\n",
            "Epoch 16/400\n",
            "1200/1200 [==============================] - 7s 6ms/step - loss: 2.9035 - policy_net_loss: 1.9791 - value_net_loss: 0.9244 - val_loss: 2.7719 - val_policy_net_loss: 1.8635 - val_value_net_loss: 0.9083\n",
            "Epoch 17/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.8865 - policy_net_loss: 1.9633 - value_net_loss: 0.9232 - val_loss: 2.7618 - val_policy_net_loss: 1.8555 - val_value_net_loss: 0.9063\n",
            "Epoch 18/400\n",
            "1200/1200 [==============================] - 7s 6ms/step - loss: 2.8812 - policy_net_loss: 1.9574 - value_net_loss: 0.9239 - val_loss: 2.7554 - val_policy_net_loss: 1.8498 - val_value_net_loss: 0.9056\n",
            "Epoch 19/400\n",
            "1200/1200 [==============================] - 7s 6ms/step - loss: 2.8655 - policy_net_loss: 1.9439 - value_net_loss: 0.9216 - val_loss: 2.7459 - val_policy_net_loss: 1.8424 - val_value_net_loss: 0.9035\n",
            "Epoch 20/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.8546 - policy_net_loss: 1.9343 - value_net_loss: 0.9203 - val_loss: 2.7417 - val_policy_net_loss: 1.8361 - val_value_net_loss: 0.9056\n",
            "Epoch 21/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.8505 - policy_net_loss: 1.9296 - value_net_loss: 0.9208 - val_loss: 2.7336 - val_policy_net_loss: 1.8291 - val_value_net_loss: 0.9046\n",
            "Epoch 22/400\n",
            "1200/1200 [==============================] - 7s 6ms/step - loss: 2.8416 - policy_net_loss: 1.9214 - value_net_loss: 0.9202 - val_loss: 2.7316 - val_policy_net_loss: 1.8276 - val_value_net_loss: 0.9040\n",
            "Epoch 23/400\n",
            "1200/1200 [==============================] - 7s 6ms/step - loss: 2.8328 - policy_net_loss: 1.9126 - value_net_loss: 0.9202 - val_loss: 2.7348 - val_policy_net_loss: 1.8293 - val_value_net_loss: 0.9055\n",
            "Epoch 24/400\n",
            "1200/1200 [==============================] - 7s 6ms/step - loss: 2.8257 - policy_net_loss: 1.9056 - value_net_loss: 0.9201 - val_loss: 2.7262 - val_policy_net_loss: 1.8192 - val_value_net_loss: 0.9069\n",
            "Epoch 25/400\n",
            "1200/1200 [==============================] - 7s 6ms/step - loss: 2.8189 - policy_net_loss: 1.9007 - value_net_loss: 0.9183 - val_loss: 2.7223 - val_policy_net_loss: 1.8200 - val_value_net_loss: 0.9023\n",
            "Epoch 26/400\n",
            "1200/1200 [==============================] - 7s 6ms/step - loss: 2.8135 - policy_net_loss: 1.8938 - value_net_loss: 0.9197 - val_loss: 2.7235 - val_policy_net_loss: 1.8232 - val_value_net_loss: 0.9003\n",
            "Epoch 27/400\n",
            "1200/1200 [==============================] - 7s 6ms/step - loss: 2.8091 - policy_net_loss: 1.8904 - value_net_loss: 0.9187 - val_loss: 2.7127 - val_policy_net_loss: 1.8117 - val_value_net_loss: 0.9010\n",
            "Epoch 28/400\n",
            "1200/1200 [==============================] - 7s 6ms/step - loss: 2.7978 - policy_net_loss: 1.8806 - value_net_loss: 0.9172 - val_loss: 2.7169 - val_policy_net_loss: 1.8151 - val_value_net_loss: 0.9018\n",
            "Epoch 29/400\n",
            "1200/1200 [==============================] - 7s 6ms/step - loss: 2.7948 - policy_net_loss: 1.8788 - value_net_loss: 0.9160 - val_loss: 2.7110 - val_policy_net_loss: 1.8103 - val_value_net_loss: 0.9007\n",
            "Epoch 30/400\n",
            "1200/1200 [==============================] - 7s 6ms/step - loss: 2.7910 - policy_net_loss: 1.8732 - value_net_loss: 0.9178 - val_loss: 2.7123 - val_policy_net_loss: 1.8095 - val_value_net_loss: 0.9028\n",
            "Epoch 31/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.7835 - policy_net_loss: 1.8665 - value_net_loss: 0.9170 - val_loss: 2.7070 - val_policy_net_loss: 1.8082 - val_value_net_loss: 0.8988\n",
            "Epoch 32/400\n",
            "1200/1200 [==============================] - 7s 6ms/step - loss: 2.7763 - policy_net_loss: 1.8616 - value_net_loss: 0.9147 - val_loss: 2.7014 - val_policy_net_loss: 1.8025 - val_value_net_loss: 0.8990\n",
            "Epoch 33/400\n",
            "1200/1200 [==============================] - 7s 6ms/step - loss: 2.7746 - policy_net_loss: 1.8596 - value_net_loss: 0.9150 - val_loss: 2.7034 - val_policy_net_loss: 1.8049 - val_value_net_loss: 0.8985\n",
            "Epoch 34/400\n",
            "1200/1200 [==============================] - 7s 6ms/step - loss: 2.7712 - policy_net_loss: 1.8571 - value_net_loss: 0.9141 - val_loss: 2.6994 - val_policy_net_loss: 1.8008 - val_value_net_loss: 0.8986\n",
            "Epoch 35/400\n",
            "1200/1200 [==============================] - 7s 6ms/step - loss: 2.7690 - policy_net_loss: 1.8543 - value_net_loss: 0.9147 - val_loss: 2.7023 - val_policy_net_loss: 1.8021 - val_value_net_loss: 0.9002\n",
            "Epoch 36/400\n",
            "1200/1200 [==============================] - 7s 6ms/step - loss: 2.7580 - policy_net_loss: 1.8450 - value_net_loss: 0.9130 - val_loss: 2.6988 - val_policy_net_loss: 1.8011 - val_value_net_loss: 0.8978\n",
            "Epoch 37/400\n",
            "1200/1200 [==============================] - 7s 6ms/step - loss: 2.7582 - policy_net_loss: 1.8445 - value_net_loss: 0.9137 - val_loss: 2.6955 - val_policy_net_loss: 1.7965 - val_value_net_loss: 0.8990\n",
            "Epoch 38/400\n",
            "1200/1200 [==============================] - 7s 6ms/step - loss: 2.7522 - policy_net_loss: 1.8393 - value_net_loss: 0.9129 - val_loss: 2.6967 - val_policy_net_loss: 1.7974 - val_value_net_loss: 0.8993\n",
            "Epoch 39/400\n",
            "1200/1200 [==============================] - 7s 6ms/step - loss: 2.7514 - policy_net_loss: 1.8385 - value_net_loss: 0.9129 - val_loss: 2.6946 - val_policy_net_loss: 1.7955 - val_value_net_loss: 0.8991\n",
            "Epoch 40/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.7463 - policy_net_loss: 1.8349 - value_net_loss: 0.9114 - val_loss: 2.6921 - val_policy_net_loss: 1.7968 - val_value_net_loss: 0.8954\n",
            "Epoch 41/400\n",
            "1200/1200 [==============================] - 7s 6ms/step - loss: 2.7408 - policy_net_loss: 1.8283 - value_net_loss: 0.9124 - val_loss: 2.6897 - val_policy_net_loss: 1.7932 - val_value_net_loss: 0.8965\n",
            "Epoch 42/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.7364 - policy_net_loss: 1.8265 - value_net_loss: 0.9099 - val_loss: 2.6888 - val_policy_net_loss: 1.7921 - val_value_net_loss: 0.8967\n",
            "Epoch 43/400\n",
            "1200/1200 [==============================] - 7s 6ms/step - loss: 2.7337 - policy_net_loss: 1.8218 - value_net_loss: 0.9118 - val_loss: 2.6882 - val_policy_net_loss: 1.7923 - val_value_net_loss: 0.8959\n",
            "Epoch 44/400\n",
            "1200/1200 [==============================] - 7s 6ms/step - loss: 2.7296 - policy_net_loss: 1.8207 - value_net_loss: 0.9088 - val_loss: 2.6863 - val_policy_net_loss: 1.7900 - val_value_net_loss: 0.8964\n",
            "Epoch 45/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.7280 - policy_net_loss: 1.8187 - value_net_loss: 0.9093 - val_loss: 2.6846 - val_policy_net_loss: 1.7887 - val_value_net_loss: 0.8959\n",
            "Epoch 46/400\n",
            "1200/1200 [==============================] - 7s 6ms/step - loss: 2.7233 - policy_net_loss: 1.8146 - value_net_loss: 0.9087 - val_loss: 2.6890 - val_policy_net_loss: 1.7908 - val_value_net_loss: 0.8982\n",
            "Epoch 47/400\n",
            "1200/1200 [==============================] - 7s 6ms/step - loss: 2.7242 - policy_net_loss: 1.8154 - value_net_loss: 0.9088 - val_loss: 2.6900 - val_policy_net_loss: 1.7944 - val_value_net_loss: 0.8956\n",
            "Epoch 48/400\n",
            "1200/1200 [==============================] - 7s 6ms/step - loss: 2.7237 - policy_net_loss: 1.8134 - value_net_loss: 0.9103 - val_loss: 2.6875 - val_policy_net_loss: 1.7914 - val_value_net_loss: 0.8961\n",
            "Epoch 49/400\n",
            "1200/1200 [==============================] - 7s 6ms/step - loss: 2.7185 - policy_net_loss: 1.8108 - value_net_loss: 0.9076 - val_loss: 2.6835 - val_policy_net_loss: 1.7886 - val_value_net_loss: 0.8948\n",
            "Epoch 50/400\n",
            "1200/1200 [==============================] - 7s 6ms/step - loss: 2.7177 - policy_net_loss: 1.8090 - value_net_loss: 0.9087 - val_loss: 2.6854 - val_policy_net_loss: 1.7887 - val_value_net_loss: 0.8967\n",
            "Epoch 51/400\n",
            "1200/1200 [==============================] - 7s 6ms/step - loss: 2.7166 - policy_net_loss: 1.8080 - value_net_loss: 0.9086 - val_loss: 2.6870 - val_policy_net_loss: 1.7870 - val_value_net_loss: 0.9000\n",
            "Epoch 52/400\n",
            "1200/1200 [==============================] - 7s 6ms/step - loss: 2.7120 - policy_net_loss: 1.8043 - value_net_loss: 0.9077 - val_loss: 2.6831 - val_policy_net_loss: 1.7874 - val_value_net_loss: 0.8957\n",
            "Epoch 53/400\n",
            "1200/1200 [==============================] - 7s 6ms/step - loss: 2.7079 - policy_net_loss: 1.7987 - value_net_loss: 0.9092 - val_loss: 2.6837 - val_policy_net_loss: 1.7864 - val_value_net_loss: 0.8974\n",
            "Epoch 54/400\n",
            "1200/1200 [==============================] - 7s 6ms/step - loss: 2.7051 - policy_net_loss: 1.7976 - value_net_loss: 0.9074 - val_loss: 2.6855 - val_policy_net_loss: 1.7868 - val_value_net_loss: 0.8987\n",
            "Epoch 55/400\n",
            "1200/1200 [==============================] - 7s 6ms/step - loss: 2.7035 - policy_net_loss: 1.7968 - value_net_loss: 0.9067 - val_loss: 2.6802 - val_policy_net_loss: 1.7862 - val_value_net_loss: 0.8940\n",
            "Epoch 56/400\n",
            "1200/1200 [==============================] - 7s 6ms/step - loss: 2.6985 - policy_net_loss: 1.7934 - value_net_loss: 0.9052 - val_loss: 2.6824 - val_policy_net_loss: 1.7822 - val_value_net_loss: 0.9002\n",
            "Epoch 57/400\n",
            "1200/1200 [==============================] - 7s 6ms/step - loss: 2.6983 - policy_net_loss: 1.7921 - value_net_loss: 0.9062 - val_loss: 2.6794 - val_policy_net_loss: 1.7836 - val_value_net_loss: 0.8958\n",
            "Epoch 58/400\n",
            "1200/1200 [==============================] - 7s 6ms/step - loss: 2.6959 - policy_net_loss: 1.7900 - value_net_loss: 0.9058 - val_loss: 2.6768 - val_policy_net_loss: 1.7834 - val_value_net_loss: 0.8934\n",
            "Epoch 59/400\n",
            "1200/1200 [==============================] - 7s 6ms/step - loss: 2.6949 - policy_net_loss: 1.7893 - value_net_loss: 0.9056 - val_loss: 2.6810 - val_policy_net_loss: 1.7885 - val_value_net_loss: 0.8925\n",
            "Epoch 60/400\n",
            "1200/1200 [==============================] - 7s 6ms/step - loss: 2.6939 - policy_net_loss: 1.7892 - value_net_loss: 0.9047 - val_loss: 2.6791 - val_policy_net_loss: 1.7862 - val_value_net_loss: 0.8929\n",
            "Epoch 61/400\n",
            "1200/1200 [==============================] - 7s 6ms/step - loss: 2.6929 - policy_net_loss: 1.7891 - value_net_loss: 0.9038 - val_loss: 2.6752 - val_policy_net_loss: 1.7811 - val_value_net_loss: 0.8941\n",
            "Epoch 62/400\n",
            "1200/1200 [==============================] - 7s 6ms/step - loss: 2.6870 - policy_net_loss: 1.7818 - value_net_loss: 0.9052 - val_loss: 2.6756 - val_policy_net_loss: 1.7826 - val_value_net_loss: 0.8931\n",
            "Epoch 63/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.6869 - policy_net_loss: 1.7819 - value_net_loss: 0.9050 - val_loss: 2.6717 - val_policy_net_loss: 1.7807 - val_value_net_loss: 0.8911\n",
            "Epoch 64/400\n",
            "1200/1200 [==============================] - 7s 6ms/step - loss: 2.6797 - policy_net_loss: 1.7770 - value_net_loss: 0.9027 - val_loss: 2.6703 - val_policy_net_loss: 1.7782 - val_value_net_loss: 0.8921\n",
            "Epoch 65/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.6819 - policy_net_loss: 1.7785 - value_net_loss: 0.9034 - val_loss: 2.6746 - val_policy_net_loss: 1.7793 - val_value_net_loss: 0.8952\n",
            "Epoch 66/400\n",
            "1200/1200 [==============================] - 7s 6ms/step - loss: 2.6806 - policy_net_loss: 1.7762 - value_net_loss: 0.9044 - val_loss: 2.6721 - val_policy_net_loss: 1.7799 - val_value_net_loss: 0.8921\n",
            "Epoch 67/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.6767 - policy_net_loss: 1.7745 - value_net_loss: 0.9023 - val_loss: 2.6743 - val_policy_net_loss: 1.7804 - val_value_net_loss: 0.8939\n",
            "Epoch 68/400\n",
            "1200/1200 [==============================] - 7s 6ms/step - loss: 2.6763 - policy_net_loss: 1.7737 - value_net_loss: 0.9027 - val_loss: 2.6692 - val_policy_net_loss: 1.7767 - val_value_net_loss: 0.8925\n",
            "Epoch 69/400\n",
            "1200/1200 [==============================] - 7s 6ms/step - loss: 2.6737 - policy_net_loss: 1.7721 - value_net_loss: 0.9016 - val_loss: 2.6741 - val_policy_net_loss: 1.7822 - val_value_net_loss: 0.8919\n",
            "Epoch 70/400\n",
            "1200/1200 [==============================] - 7s 6ms/step - loss: 2.6761 - policy_net_loss: 1.7734 - value_net_loss: 0.9027 - val_loss: 2.6777 - val_policy_net_loss: 1.7829 - val_value_net_loss: 0.8948\n",
            "Epoch 71/400\n",
            "1200/1200 [==============================] - 7s 6ms/step - loss: 2.6746 - policy_net_loss: 1.7729 - value_net_loss: 0.9017 - val_loss: 2.6725 - val_policy_net_loss: 1.7808 - val_value_net_loss: 0.8916\n",
            "Epoch 72/400\n",
            "1200/1200 [==============================] - 7s 6ms/step - loss: 2.6696 - policy_net_loss: 1.7672 - value_net_loss: 0.9024 - val_loss: 2.6761 - val_policy_net_loss: 1.7834 - val_value_net_loss: 0.8927\n",
            "Epoch 73/400\n",
            "1200/1200 [==============================] - 7s 6ms/step - loss: 2.6719 - policy_net_loss: 1.7694 - value_net_loss: 0.9025 - val_loss: 2.6768 - val_policy_net_loss: 1.7825 - val_value_net_loss: 0.8943\n",
            "Epoch 74/400\n",
            "1200/1200 [==============================] - 7s 6ms/step - loss: 2.6674 - policy_net_loss: 1.7640 - value_net_loss: 0.9034 - val_loss: 2.6758 - val_policy_net_loss: 1.7835 - val_value_net_loss: 0.8923\n",
            "Epoch 75/400\n",
            "1200/1200 [==============================] - 7s 6ms/step - loss: 2.6606 - policy_net_loss: 1.7600 - value_net_loss: 0.9006 - val_loss: 2.6780 - val_policy_net_loss: 1.7830 - val_value_net_loss: 0.8950\n",
            "Epoch 76/400\n",
            "1200/1200 [==============================] - 7s 6ms/step - loss: 2.6595 - policy_net_loss: 1.7585 - value_net_loss: 0.9010 - val_loss: 2.6761 - val_policy_net_loss: 1.7842 - val_value_net_loss: 0.8919\n",
            "Epoch 77/400\n",
            "1200/1200 [==============================] - 7s 6ms/step - loss: 2.6609 - policy_net_loss: 1.7602 - value_net_loss: 0.9007 - val_loss: 2.6764 - val_policy_net_loss: 1.7834 - val_value_net_loss: 0.8930\n",
            "Epoch 78/400\n",
            "1200/1200 [==============================] - 7s 6ms/step - loss: 2.6605 - policy_net_loss: 1.7600 - value_net_loss: 0.9004 - val_loss: 2.6783 - val_policy_net_loss: 1.7830 - val_value_net_loss: 0.8953\n",
            "Epoch 79/400\n",
            "1200/1200 [==============================] - 7s 6ms/step - loss: 2.6588 - policy_net_loss: 1.7584 - value_net_loss: 0.9005 - val_loss: 2.6747 - val_policy_net_loss: 1.7789 - val_value_net_loss: 0.8958\n",
            "Epoch 80/400\n",
            "1200/1200 [==============================] - 7s 6ms/step - loss: 2.6570 - policy_net_loss: 1.7578 - value_net_loss: 0.8993 - val_loss: 2.6707 - val_policy_net_loss: 1.7791 - val_value_net_loss: 0.8916\n",
            "Epoch 81/400\n",
            "1200/1200 [==============================] - 7s 6ms/step - loss: 2.6532 - policy_net_loss: 1.7528 - value_net_loss: 0.9004 - val_loss: 2.6793 - val_policy_net_loss: 1.7868 - val_value_net_loss: 0.8926\n",
            "Epoch 82/400\n",
            "1200/1200 [==============================] - 7s 6ms/step - loss: 2.6562 - policy_net_loss: 1.7553 - value_net_loss: 0.9010 - val_loss: 2.6806 - val_policy_net_loss: 1.7865 - val_value_net_loss: 0.8941\n",
            "Epoch 83/400\n",
            "1200/1200 [==============================] - 7s 6ms/step - loss: 2.6535 - policy_net_loss: 1.7529 - value_net_loss: 0.9006 - val_loss: 2.6774 - val_policy_net_loss: 1.7831 - val_value_net_loss: 0.8943\n",
            "Epoch 84/400\n",
            "1200/1200 [==============================] - 7s 6ms/step - loss: 2.6537 - policy_net_loss: 1.7557 - value_net_loss: 0.8980 - val_loss: 2.6759 - val_policy_net_loss: 1.7813 - val_value_net_loss: 0.8946\n",
            "Epoch 85/400\n",
            "1200/1200 [==============================] - 7s 6ms/step - loss: 2.6497 - policy_net_loss: 1.7507 - value_net_loss: 0.8990 - val_loss: 2.6726 - val_policy_net_loss: 1.7803 - val_value_net_loss: 0.8923\n",
            "Epoch 86/400\n",
            "1200/1200 [==============================] - 8s 6ms/step - loss: 2.6496 - policy_net_loss: 1.7504 - value_net_loss: 0.8992 - val_loss: 2.6753 - val_policy_net_loss: 1.7823 - val_value_net_loss: 0.8930\n",
            "Epoch 87/400\n",
            "1200/1200 [==============================] - 8s 6ms/step - loss: 2.6442 - policy_net_loss: 1.7455 - value_net_loss: 0.8987 - val_loss: 2.6718 - val_policy_net_loss: 1.7799 - val_value_net_loss: 0.8919\n",
            "Epoch 88/400\n",
            "1200/1200 [==============================] - 8s 6ms/step - loss: 2.6438 - policy_net_loss: 1.7463 - value_net_loss: 0.8975 - val_loss: 2.6787 - val_policy_net_loss: 1.7831 - val_value_net_loss: 0.8956\n",
            "Epoch 89/400\n",
            "1200/1200 [==============================] - 7s 6ms/step - loss: 2.6415 - policy_net_loss: 1.7423 - value_net_loss: 0.8992 - val_loss: 2.6728 - val_policy_net_loss: 1.7811 - val_value_net_loss: 0.8918\n",
            "Epoch 90/400\n",
            "1200/1200 [==============================] - 7s 6ms/step - loss: 2.6468 - policy_net_loss: 1.7486 - value_net_loss: 0.8982 - val_loss: 2.6720 - val_policy_net_loss: 1.7798 - val_value_net_loss: 0.8922\n",
            "Epoch 91/400\n",
            "1200/1200 [==============================] - 7s 6ms/step - loss: 2.6402 - policy_net_loss: 1.7430 - value_net_loss: 0.8971 - val_loss: 2.6685 - val_policy_net_loss: 1.7768 - val_value_net_loss: 0.8917\n",
            "Epoch 92/400\n",
            "1200/1200 [==============================] - 7s 6ms/step - loss: 2.6468 - policy_net_loss: 1.7487 - value_net_loss: 0.8980 - val_loss: 2.6712 - val_policy_net_loss: 1.7783 - val_value_net_loss: 0.8930\n",
            "Epoch 93/400\n",
            "1200/1200 [==============================] - 8s 6ms/step - loss: 2.6432 - policy_net_loss: 1.7445 - value_net_loss: 0.8986 - val_loss: 2.6723 - val_policy_net_loss: 1.7796 - val_value_net_loss: 0.8927\n",
            "Epoch 94/400\n",
            "1200/1200 [==============================] - 7s 6ms/step - loss: 2.6380 - policy_net_loss: 1.7406 - value_net_loss: 0.8975 - val_loss: 2.6773 - val_policy_net_loss: 1.7832 - val_value_net_loss: 0.8941\n",
            "Epoch 95/400\n",
            "1200/1200 [==============================] - 8s 6ms/step - loss: 2.6386 - policy_net_loss: 1.7422 - value_net_loss: 0.8964 - val_loss: 2.6760 - val_policy_net_loss: 1.7805 - val_value_net_loss: 0.8956\n",
            "Epoch 96/400\n",
            "1200/1200 [==============================] - 7s 6ms/step - loss: 2.6344 - policy_net_loss: 1.7377 - value_net_loss: 0.8967 - val_loss: 2.6701 - val_policy_net_loss: 1.7796 - val_value_net_loss: 0.8905\n",
            "Epoch 97/400\n",
            "1200/1200 [==============================] - 7s 6ms/step - loss: 2.6356 - policy_net_loss: 1.7393 - value_net_loss: 0.8963 - val_loss: 2.6725 - val_policy_net_loss: 1.7804 - val_value_net_loss: 0.8920\n",
            "Epoch 98/400\n",
            "1200/1200 [==============================] - 8s 6ms/step - loss: 2.6332 - policy_net_loss: 1.7363 - value_net_loss: 0.8969 - val_loss: 2.6721 - val_policy_net_loss: 1.7806 - val_value_net_loss: 0.8915\n",
            "Epoch 99/400\n",
            "1200/1200 [==============================] - 7s 6ms/step - loss: 2.6344 - policy_net_loss: 1.7374 - value_net_loss: 0.8970 - val_loss: 2.6757 - val_policy_net_loss: 1.7843 - val_value_net_loss: 0.8915\n",
            "Epoch 100/400\n",
            "1200/1200 [==============================] - 8s 6ms/step - loss: 2.6329 - policy_net_loss: 1.7369 - value_net_loss: 0.8959 - val_loss: 2.6779 - val_policy_net_loss: 1.7816 - val_value_net_loss: 0.8963\n",
            "Epoch 101/400\n",
            "1200/1200 [==============================] - 8s 6ms/step - loss: 2.6288 - policy_net_loss: 1.7326 - value_net_loss: 0.8962 - val_loss: 2.6817 - val_policy_net_loss: 1.7815 - val_value_net_loss: 0.9001\n",
            "Epoch 102/400\n",
            "1200/1200 [==============================] - 8s 6ms/step - loss: 2.6305 - policy_net_loss: 1.7345 - value_net_loss: 0.8960 - val_loss: 2.6777 - val_policy_net_loss: 1.7826 - val_value_net_loss: 0.8951\n",
            "Epoch 103/400\n",
            "1200/1200 [==============================] - 8s 6ms/step - loss: 2.6305 - policy_net_loss: 1.7354 - value_net_loss: 0.8951 - val_loss: 2.6738 - val_policy_net_loss: 1.7817 - val_value_net_loss: 0.8921\n",
            "Epoch 104/400\n",
            "1200/1200 [==============================] - 8s 6ms/step - loss: 2.6263 - policy_net_loss: 1.7314 - value_net_loss: 0.8949 - val_loss: 2.6722 - val_policy_net_loss: 1.7805 - val_value_net_loss: 0.8917\n",
            "Epoch 105/400\n",
            "1200/1200 [==============================] - 8s 6ms/step - loss: 2.6261 - policy_net_loss: 1.7309 - value_net_loss: 0.8952 - val_loss: 2.6738 - val_policy_net_loss: 1.7819 - val_value_net_loss: 0.8919\n",
            "Epoch 106/400\n",
            "1200/1200 [==============================] - 8s 6ms/step - loss: 2.6252 - policy_net_loss: 1.7297 - value_net_loss: 0.8955 - val_loss: 2.6697 - val_policy_net_loss: 1.7798 - val_value_net_loss: 0.8900\n",
            "Epoch 107/400\n",
            "1200/1200 [==============================] - 7s 6ms/step - loss: 2.6260 - policy_net_loss: 1.7300 - value_net_loss: 0.8960 - val_loss: 2.6730 - val_policy_net_loss: 1.7813 - val_value_net_loss: 0.8917\n",
            "Epoch 108/400\n",
            "1200/1200 [==============================] - 7s 6ms/step - loss: 2.6248 - policy_net_loss: 1.7304 - value_net_loss: 0.8944 - val_loss: 2.6711 - val_policy_net_loss: 1.7805 - val_value_net_loss: 0.8905\n",
            "Epoch 109/400\n",
            "1200/1200 [==============================] - 7s 6ms/step - loss: 2.6254 - policy_net_loss: 1.7306 - value_net_loss: 0.8949 - val_loss: 2.6754 - val_policy_net_loss: 1.7838 - val_value_net_loss: 0.8916\n",
            "Epoch 110/400\n",
            "1200/1200 [==============================] - 7s 6ms/step - loss: 2.6281 - policy_net_loss: 1.7324 - value_net_loss: 0.8956 - val_loss: 2.6746 - val_policy_net_loss: 1.7828 - val_value_net_loss: 0.8919\n",
            "Epoch 111/400\n",
            "1200/1200 [==============================] - 7s 6ms/step - loss: 2.6234 - policy_net_loss: 1.7283 - value_net_loss: 0.8951 - val_loss: 2.6766 - val_policy_net_loss: 1.7830 - val_value_net_loss: 0.8936\n",
            "Epoch 112/400\n",
            "1200/1200 [==============================] - 7s 6ms/step - loss: 2.6231 - policy_net_loss: 1.7280 - value_net_loss: 0.8951 - val_loss: 2.6720 - val_policy_net_loss: 1.7806 - val_value_net_loss: 0.8914\n",
            "Epoch 113/400\n",
            "1200/1200 [==============================] - 7s 6ms/step - loss: 2.6233 - policy_net_loss: 1.7283 - value_net_loss: 0.8950 - val_loss: 2.6727 - val_policy_net_loss: 1.7818 - val_value_net_loss: 0.8909\n",
            "Epoch 114/400\n",
            "1200/1200 [==============================] - 7s 6ms/step - loss: 2.6162 - policy_net_loss: 1.7226 - value_net_loss: 0.8937 - val_loss: 2.6731 - val_policy_net_loss: 1.7822 - val_value_net_loss: 0.8908\n",
            "Epoch 115/400\n",
            "1200/1200 [==============================] - 8s 6ms/step - loss: 2.6196 - policy_net_loss: 1.7256 - value_net_loss: 0.8940 - val_loss: 2.6721 - val_policy_net_loss: 1.7811 - val_value_net_loss: 0.8911\n",
            "Epoch 116/400\n",
            "1200/1200 [==============================] - 8s 6ms/step - loss: 2.6133 - policy_net_loss: 1.7210 - value_net_loss: 0.8924 - val_loss: 2.6733 - val_policy_net_loss: 1.7821 - val_value_net_loss: 0.8912\n",
            "Epoch 117/400\n",
            "1200/1200 [==============================] - 8s 6ms/step - loss: 2.6167 - policy_net_loss: 1.7240 - value_net_loss: 0.8927 - val_loss: 2.6698 - val_policy_net_loss: 1.7789 - val_value_net_loss: 0.8908\n",
            "Epoch 118/400\n",
            "1200/1200 [==============================] - 8s 6ms/step - loss: 2.6184 - policy_net_loss: 1.7244 - value_net_loss: 0.8940 - val_loss: 2.6769 - val_policy_net_loss: 1.7847 - val_value_net_loss: 0.8921\n",
            "Epoch 119/400\n",
            "1200/1200 [==============================] - 8s 6ms/step - loss: 2.6129 - policy_net_loss: 1.7194 - value_net_loss: 0.8935 - val_loss: 2.6770 - val_policy_net_loss: 1.7855 - val_value_net_loss: 0.8914\n",
            "Epoch 120/400\n",
            "1200/1200 [==============================] - 8s 6ms/step - loss: 2.6117 - policy_net_loss: 1.7187 - value_net_loss: 0.8930 - val_loss: 2.6722 - val_policy_net_loss: 1.7811 - val_value_net_loss: 0.8911\n",
            "Epoch 121/400\n",
            "1200/1200 [==============================] - 8s 6ms/step - loss: 2.6162 - policy_net_loss: 1.7215 - value_net_loss: 0.8947 - val_loss: 2.6743 - val_policy_net_loss: 1.7834 - val_value_net_loss: 0.8909\n",
            "Epoch 122/400\n",
            "1200/1200 [==============================] - 8s 6ms/step - loss: 2.6151 - policy_net_loss: 1.7213 - value_net_loss: 0.8937 - val_loss: 2.6828 - val_policy_net_loss: 1.7838 - val_value_net_loss: 0.8990\n",
            "Epoch 123/400\n",
            "1200/1200 [==============================] - 8s 6ms/step - loss: 2.6089 - policy_net_loss: 1.7165 - value_net_loss: 0.8924 - val_loss: 2.6768 - val_policy_net_loss: 1.7850 - val_value_net_loss: 0.8917\n",
            "Epoch 124/400\n",
            "1200/1200 [==============================] - 8s 6ms/step - loss: 2.6139 - policy_net_loss: 1.7208 - value_net_loss: 0.8931 - val_loss: 2.6768 - val_policy_net_loss: 1.7860 - val_value_net_loss: 0.8909\n",
            "Epoch 125/400\n",
            "1200/1200 [==============================] - 8s 6ms/step - loss: 2.6167 - policy_net_loss: 1.7225 - value_net_loss: 0.8942 - val_loss: 2.6771 - val_policy_net_loss: 1.7822 - val_value_net_loss: 0.8948\n",
            "Epoch 126/400\n",
            "1200/1200 [==============================] - 8s 6ms/step - loss: 2.6083 - policy_net_loss: 1.7161 - value_net_loss: 0.8922 - val_loss: 2.6763 - val_policy_net_loss: 1.7841 - val_value_net_loss: 0.8921\n",
            "Epoch 127/400\n",
            "1200/1200 [==============================] - 8s 6ms/step - loss: 2.6111 - policy_net_loss: 1.7183 - value_net_loss: 0.8928 - val_loss: 2.6747 - val_policy_net_loss: 1.7836 - val_value_net_loss: 0.8911\n",
            "Epoch 128/400\n",
            "1200/1200 [==============================] - 8s 6ms/step - loss: 2.6073 - policy_net_loss: 1.7162 - value_net_loss: 0.8911 - val_loss: 2.6781 - val_policy_net_loss: 1.7863 - val_value_net_loss: 0.8918\n",
            "Epoch 129/400\n",
            "1200/1200 [==============================] - 8s 6ms/step - loss: 2.6076 - policy_net_loss: 1.7168 - value_net_loss: 0.8907 - val_loss: 2.6763 - val_policy_net_loss: 1.7849 - val_value_net_loss: 0.8914\n",
            "Epoch 130/400\n",
            "1200/1200 [==============================] - 8s 6ms/step - loss: 2.6076 - policy_net_loss: 1.7152 - value_net_loss: 0.8923 - val_loss: 2.6806 - val_policy_net_loss: 1.7884 - val_value_net_loss: 0.8923\n",
            "Epoch 131/400\n",
            "1200/1200 [==============================] - 8s 6ms/step - loss: 2.6017 - policy_net_loss: 1.7114 - value_net_loss: 0.8902 - val_loss: 2.6810 - val_policy_net_loss: 1.7898 - val_value_net_loss: 0.8912\n",
            "Epoch 132/400\n",
            "1200/1200 [==============================] - 8s 6ms/step - loss: 2.6021 - policy_net_loss: 1.7128 - value_net_loss: 0.8893 - val_loss: 2.6769 - val_policy_net_loss: 1.7845 - val_value_net_loss: 0.8924\n",
            "Epoch 133/400\n",
            "1200/1200 [==============================] - 8s 6ms/step - loss: 2.6018 - policy_net_loss: 1.7107 - value_net_loss: 0.8911 - val_loss: 2.6776 - val_policy_net_loss: 1.7864 - val_value_net_loss: 0.8911\n",
            "Epoch 134/400\n",
            "1200/1200 [==============================] - 8s 6ms/step - loss: 2.6015 - policy_net_loss: 1.7089 - value_net_loss: 0.8926 - val_loss: 2.6826 - val_policy_net_loss: 1.7907 - val_value_net_loss: 0.8919\n",
            "Epoch 135/400\n",
            "1200/1200 [==============================] - 8s 6ms/step - loss: 2.6005 - policy_net_loss: 1.7117 - value_net_loss: 0.8889 - val_loss: 2.6831 - val_policy_net_loss: 1.7883 - val_value_net_loss: 0.8948\n",
            "Epoch 136/400\n",
            "1200/1200 [==============================] - 8s 6ms/step - loss: 2.6005 - policy_net_loss: 1.7120 - value_net_loss: 0.8885 - val_loss: 2.6763 - val_policy_net_loss: 1.7843 - val_value_net_loss: 0.8920\n",
            "Epoch 137/400\n",
            "1200/1200 [==============================] - 8s 6ms/step - loss: 2.6055 - policy_net_loss: 1.7141 - value_net_loss: 0.8914 - val_loss: 2.6760 - val_policy_net_loss: 1.7843 - val_value_net_loss: 0.8917\n",
            "Epoch 138/400\n",
            "1200/1200 [==============================] - 8s 6ms/step - loss: 2.6025 - policy_net_loss: 1.7119 - value_net_loss: 0.8905 - val_loss: 2.6802 - val_policy_net_loss: 1.7878 - val_value_net_loss: 0.8924\n",
            "Epoch 139/400\n",
            "1200/1200 [==============================] - 8s 6ms/step - loss: 2.5953 - policy_net_loss: 1.7073 - value_net_loss: 0.8880 - val_loss: 2.6798 - val_policy_net_loss: 1.7879 - val_value_net_loss: 0.8919\n",
            "Epoch 140/400\n",
            "1200/1200 [==============================] - 8s 6ms/step - loss: 2.6019 - policy_net_loss: 1.7130 - value_net_loss: 0.8888 - val_loss: 2.6764 - val_policy_net_loss: 1.7837 - val_value_net_loss: 0.8928\n",
            "Epoch 141/400\n",
            "1200/1200 [==============================] - 8s 6ms/step - loss: 2.5984 - policy_net_loss: 1.7107 - value_net_loss: 0.8878 - val_loss: 2.6754 - val_policy_net_loss: 1.7847 - val_value_net_loss: 0.8907\n",
            "Epoch 142/400\n",
            "1200/1200 [==============================] - 8s 6ms/step - loss: 2.5951 - policy_net_loss: 1.7071 - value_net_loss: 0.8880 - val_loss: 2.6750 - val_policy_net_loss: 1.7850 - val_value_net_loss: 0.8899\n",
            "Epoch 143/400\n",
            "1200/1200 [==============================] - 8s 6ms/step - loss: 2.5953 - policy_net_loss: 1.7056 - value_net_loss: 0.8897 - val_loss: 2.6778 - val_policy_net_loss: 1.7864 - val_value_net_loss: 0.8914\n",
            "Epoch 144/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.6018 - policy_net_loss: 1.7122 - value_net_loss: 0.8896 - val_loss: 2.6784 - val_policy_net_loss: 1.7868 - val_value_net_loss: 0.8916\n",
            "Epoch 145/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5959 - policy_net_loss: 1.7069 - value_net_loss: 0.8890 - val_loss: 2.6772 - val_policy_net_loss: 1.7863 - val_value_net_loss: 0.8909\n",
            "Epoch 146/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5969 - policy_net_loss: 1.7070 - value_net_loss: 0.8899 - val_loss: 2.6771 - val_policy_net_loss: 1.7866 - val_value_net_loss: 0.8905\n",
            "Epoch 147/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5975 - policy_net_loss: 1.7094 - value_net_loss: 0.8882 - val_loss: 2.6779 - val_policy_net_loss: 1.7863 - val_value_net_loss: 0.8916\n",
            "Epoch 148/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5911 - policy_net_loss: 1.7028 - value_net_loss: 0.8883 - val_loss: 2.6780 - val_policy_net_loss: 1.7879 - val_value_net_loss: 0.8900\n",
            "Epoch 149/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5938 - policy_net_loss: 1.7056 - value_net_loss: 0.8881 - val_loss: 2.6791 - val_policy_net_loss: 1.7870 - val_value_net_loss: 0.8921\n",
            "Epoch 150/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5924 - policy_net_loss: 1.7047 - value_net_loss: 0.8877 - val_loss: 2.6804 - val_policy_net_loss: 1.7887 - val_value_net_loss: 0.8917\n",
            "Epoch 151/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5895 - policy_net_loss: 1.7023 - value_net_loss: 0.8873 - val_loss: 2.6785 - val_policy_net_loss: 1.7869 - val_value_net_loss: 0.8916\n",
            "Epoch 152/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5842 - policy_net_loss: 1.6987 - value_net_loss: 0.8856 - val_loss: 2.6795 - val_policy_net_loss: 1.7867 - val_value_net_loss: 0.8928\n",
            "Epoch 153/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5883 - policy_net_loss: 1.7022 - value_net_loss: 0.8862 - val_loss: 2.6788 - val_policy_net_loss: 1.7872 - val_value_net_loss: 0.8916\n",
            "Epoch 154/400\n",
            "1200/1200 [==============================] - 8s 6ms/step - loss: 2.5848 - policy_net_loss: 1.6979 - value_net_loss: 0.8869 - val_loss: 2.6778 - val_policy_net_loss: 1.7878 - val_value_net_loss: 0.8900\n",
            "Epoch 155/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5840 - policy_net_loss: 1.6969 - value_net_loss: 0.8871 - val_loss: 2.6764 - val_policy_net_loss: 1.7862 - val_value_net_loss: 0.8902\n",
            "Epoch 156/400\n",
            "1200/1200 [==============================] - 8s 6ms/step - loss: 2.5920 - policy_net_loss: 1.7032 - value_net_loss: 0.8888 - val_loss: 2.6743 - val_policy_net_loss: 1.7836 - val_value_net_loss: 0.8907\n",
            "Epoch 157/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5867 - policy_net_loss: 1.7001 - value_net_loss: 0.8866 - val_loss: 2.6773 - val_policy_net_loss: 1.7867 - val_value_net_loss: 0.8907\n",
            "Epoch 158/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5902 - policy_net_loss: 1.7030 - value_net_loss: 0.8872 - val_loss: 2.6783 - val_policy_net_loss: 1.7874 - val_value_net_loss: 0.8909\n",
            "Epoch 159/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5846 - policy_net_loss: 1.6997 - value_net_loss: 0.8849 - val_loss: 2.6825 - val_policy_net_loss: 1.7913 - val_value_net_loss: 0.8912\n",
            "Epoch 160/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5896 - policy_net_loss: 1.7026 - value_net_loss: 0.8870 - val_loss: 2.6775 - val_policy_net_loss: 1.7871 - val_value_net_loss: 0.8904\n",
            "Epoch 161/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5897 - policy_net_loss: 1.7022 - value_net_loss: 0.8875 - val_loss: 2.6758 - val_policy_net_loss: 1.7847 - val_value_net_loss: 0.8911\n",
            "Epoch 162/400\n",
            "1200/1200 [==============================] - 8s 6ms/step - loss: 2.5815 - policy_net_loss: 1.6970 - value_net_loss: 0.8845 - val_loss: 2.6777 - val_policy_net_loss: 1.7850 - val_value_net_loss: 0.8927\n",
            "Epoch 163/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5860 - policy_net_loss: 1.6985 - value_net_loss: 0.8875 - val_loss: 2.6776 - val_policy_net_loss: 1.7851 - val_value_net_loss: 0.8925\n",
            "Epoch 164/400\n",
            "1200/1200 [==============================] - 8s 6ms/step - loss: 2.5777 - policy_net_loss: 1.6938 - value_net_loss: 0.8839 - val_loss: 2.6765 - val_policy_net_loss: 1.7864 - val_value_net_loss: 0.8902\n",
            "Epoch 165/400\n",
            "1200/1200 [==============================] - 8s 6ms/step - loss: 2.5791 - policy_net_loss: 1.6916 - value_net_loss: 0.8875 - val_loss: 2.6815 - val_policy_net_loss: 1.7915 - val_value_net_loss: 0.8900\n",
            "Epoch 166/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5790 - policy_net_loss: 1.6936 - value_net_loss: 0.8854 - val_loss: 2.6779 - val_policy_net_loss: 1.7867 - val_value_net_loss: 0.8912\n",
            "Epoch 167/400\n",
            "1200/1200 [==============================] - 8s 6ms/step - loss: 2.5799 - policy_net_loss: 1.6944 - value_net_loss: 0.8855 - val_loss: 2.6798 - val_policy_net_loss: 1.7905 - val_value_net_loss: 0.8893\n",
            "Epoch 168/400\n",
            "1200/1200 [==============================] - 8s 6ms/step - loss: 2.5774 - policy_net_loss: 1.6923 - value_net_loss: 0.8852 - val_loss: 2.6755 - val_policy_net_loss: 1.7853 - val_value_net_loss: 0.8902\n",
            "Epoch 169/400\n",
            "1200/1200 [==============================] - 8s 6ms/step - loss: 2.5790 - policy_net_loss: 1.6938 - value_net_loss: 0.8853 - val_loss: 2.6838 - val_policy_net_loss: 1.7919 - val_value_net_loss: 0.8919\n",
            "Epoch 170/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5822 - policy_net_loss: 1.6968 - value_net_loss: 0.8854 - val_loss: 2.6820 - val_policy_net_loss: 1.7894 - val_value_net_loss: 0.8926\n",
            "Epoch 171/400\n",
            "1200/1200 [==============================] - 8s 6ms/step - loss: 2.5790 - policy_net_loss: 1.6949 - value_net_loss: 0.8841 - val_loss: 2.6778 - val_policy_net_loss: 1.7876 - val_value_net_loss: 0.8902\n",
            "Epoch 172/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5810 - policy_net_loss: 1.6960 - value_net_loss: 0.8850 - val_loss: 2.6780 - val_policy_net_loss: 1.7873 - val_value_net_loss: 0.8908\n",
            "Epoch 173/400\n",
            "1200/1200 [==============================] - 8s 6ms/step - loss: 2.5805 - policy_net_loss: 1.6963 - value_net_loss: 0.8842 - val_loss: 2.6799 - val_policy_net_loss: 1.7891 - val_value_net_loss: 0.8908\n",
            "Epoch 174/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5761 - policy_net_loss: 1.6922 - value_net_loss: 0.8838 - val_loss: 2.6792 - val_policy_net_loss: 1.7864 - val_value_net_loss: 0.8928\n",
            "Epoch 175/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5774 - policy_net_loss: 1.6919 - value_net_loss: 0.8855 - val_loss: 2.6811 - val_policy_net_loss: 1.7896 - val_value_net_loss: 0.8915\n",
            "Epoch 176/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5763 - policy_net_loss: 1.6938 - value_net_loss: 0.8826 - val_loss: 2.6804 - val_policy_net_loss: 1.7883 - val_value_net_loss: 0.8921\n",
            "Epoch 177/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5746 - policy_net_loss: 1.6899 - value_net_loss: 0.8847 - val_loss: 2.6836 - val_policy_net_loss: 1.7905 - val_value_net_loss: 0.8930\n",
            "Epoch 178/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5753 - policy_net_loss: 1.6909 - value_net_loss: 0.8844 - val_loss: 2.6819 - val_policy_net_loss: 1.7881 - val_value_net_loss: 0.8939\n",
            "Epoch 179/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5779 - policy_net_loss: 1.6952 - value_net_loss: 0.8828 - val_loss: 2.6775 - val_policy_net_loss: 1.7857 - val_value_net_loss: 0.8918\n",
            "Epoch 180/400\n",
            "1200/1200 [==============================] - 9s 7ms/step - loss: 2.5757 - policy_net_loss: 1.6928 - value_net_loss: 0.8829 - val_loss: 2.6805 - val_policy_net_loss: 1.7887 - val_value_net_loss: 0.8918\n",
            "Epoch 181/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5711 - policy_net_loss: 1.6889 - value_net_loss: 0.8822 - val_loss: 2.6854 - val_policy_net_loss: 1.7915 - val_value_net_loss: 0.8939\n",
            "Epoch 182/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5768 - policy_net_loss: 1.6928 - value_net_loss: 0.8840 - val_loss: 2.6824 - val_policy_net_loss: 1.7895 - val_value_net_loss: 0.8929\n",
            "Epoch 183/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5688 - policy_net_loss: 1.6857 - value_net_loss: 0.8831 - val_loss: 2.6818 - val_policy_net_loss: 1.7901 - val_value_net_loss: 0.8917\n",
            "Epoch 184/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5780 - policy_net_loss: 1.6944 - value_net_loss: 0.8837 - val_loss: 2.6806 - val_policy_net_loss: 1.7896 - val_value_net_loss: 0.8911\n",
            "Epoch 185/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5756 - policy_net_loss: 1.6906 - value_net_loss: 0.8850 - val_loss: 2.6771 - val_policy_net_loss: 1.7855 - val_value_net_loss: 0.8915\n",
            "Epoch 186/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5736 - policy_net_loss: 1.6911 - value_net_loss: 0.8825 - val_loss: 2.6764 - val_policy_net_loss: 1.7851 - val_value_net_loss: 0.8913\n",
            "Epoch 187/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5714 - policy_net_loss: 1.6872 - value_net_loss: 0.8842 - val_loss: 2.6774 - val_policy_net_loss: 1.7873 - val_value_net_loss: 0.8901\n",
            "Epoch 188/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5663 - policy_net_loss: 1.6849 - value_net_loss: 0.8815 - val_loss: 2.6802 - val_policy_net_loss: 1.7874 - val_value_net_loss: 0.8928\n",
            "Epoch 189/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5691 - policy_net_loss: 1.6879 - value_net_loss: 0.8812 - val_loss: 2.6836 - val_policy_net_loss: 1.7934 - val_value_net_loss: 0.8903\n",
            "Epoch 190/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5668 - policy_net_loss: 1.6837 - value_net_loss: 0.8831 - val_loss: 2.6801 - val_policy_net_loss: 1.7876 - val_value_net_loss: 0.8925\n",
            "Epoch 191/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5706 - policy_net_loss: 1.6880 - value_net_loss: 0.8826 - val_loss: 2.6820 - val_policy_net_loss: 1.7900 - val_value_net_loss: 0.8920\n",
            "Epoch 192/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5672 - policy_net_loss: 1.6873 - value_net_loss: 0.8800 - val_loss: 2.6846 - val_policy_net_loss: 1.7912 - val_value_net_loss: 0.8934\n",
            "Epoch 193/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5645 - policy_net_loss: 1.6822 - value_net_loss: 0.8823 - val_loss: 2.6830 - val_policy_net_loss: 1.7930 - val_value_net_loss: 0.8901\n",
            "Epoch 194/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5683 - policy_net_loss: 1.6872 - value_net_loss: 0.8811 - val_loss: 2.6817 - val_policy_net_loss: 1.7900 - val_value_net_loss: 0.8917\n",
            "Epoch 195/400\n",
            "1200/1200 [==============================] - 8s 6ms/step - loss: 2.5634 - policy_net_loss: 1.6839 - value_net_loss: 0.8795 - val_loss: 2.6848 - val_policy_net_loss: 1.7930 - val_value_net_loss: 0.8918\n",
            "Epoch 196/400\n",
            "1200/1200 [==============================] - 8s 6ms/step - loss: 2.5690 - policy_net_loss: 1.6870 - value_net_loss: 0.8820 - val_loss: 2.6877 - val_policy_net_loss: 1.7968 - val_value_net_loss: 0.8909\n",
            "Epoch 197/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5624 - policy_net_loss: 1.6820 - value_net_loss: 0.8804 - val_loss: 2.6842 - val_policy_net_loss: 1.7929 - val_value_net_loss: 0.8913\n",
            "Epoch 198/400\n",
            "1200/1200 [==============================] - 8s 6ms/step - loss: 2.5719 - policy_net_loss: 1.6905 - value_net_loss: 0.8814 - val_loss: 2.6794 - val_policy_net_loss: 1.7878 - val_value_net_loss: 0.8916\n",
            "Epoch 199/400\n",
            "1200/1200 [==============================] - 8s 6ms/step - loss: 2.5604 - policy_net_loss: 1.6804 - value_net_loss: 0.8800 - val_loss: 2.6793 - val_policy_net_loss: 1.7868 - val_value_net_loss: 0.8926\n",
            "Epoch 200/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5653 - policy_net_loss: 1.6852 - value_net_loss: 0.8800 - val_loss: 2.6832 - val_policy_net_loss: 1.7921 - val_value_net_loss: 0.8911\n",
            "Epoch 201/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5691 - policy_net_loss: 1.6867 - value_net_loss: 0.8823 - val_loss: 2.6872 - val_policy_net_loss: 1.7952 - val_value_net_loss: 0.8920\n",
            "Epoch 202/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5659 - policy_net_loss: 1.6860 - value_net_loss: 0.8800 - val_loss: 2.6805 - val_policy_net_loss: 1.7903 - val_value_net_loss: 0.8902\n",
            "Epoch 203/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5629 - policy_net_loss: 1.6819 - value_net_loss: 0.8810 - val_loss: 2.6828 - val_policy_net_loss: 1.7920 - val_value_net_loss: 0.8908\n",
            "Epoch 204/400\n",
            "1200/1200 [==============================] - 9s 7ms/step - loss: 2.5627 - policy_net_loss: 1.6812 - value_net_loss: 0.8815 - val_loss: 2.6830 - val_policy_net_loss: 1.7908 - val_value_net_loss: 0.8922\n",
            "Epoch 205/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5571 - policy_net_loss: 1.6786 - value_net_loss: 0.8785 - val_loss: 2.6806 - val_policy_net_loss: 1.7881 - val_value_net_loss: 0.8925\n",
            "Epoch 206/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5613 - policy_net_loss: 1.6807 - value_net_loss: 0.8806 - val_loss: 2.6833 - val_policy_net_loss: 1.7918 - val_value_net_loss: 0.8915\n",
            "Epoch 207/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5634 - policy_net_loss: 1.6831 - value_net_loss: 0.8803 - val_loss: 2.6868 - val_policy_net_loss: 1.7939 - val_value_net_loss: 0.8929\n",
            "Epoch 208/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5617 - policy_net_loss: 1.6834 - value_net_loss: 0.8784 - val_loss: 2.6863 - val_policy_net_loss: 1.7934 - val_value_net_loss: 0.8929\n",
            "Epoch 209/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5638 - policy_net_loss: 1.6835 - value_net_loss: 0.8803 - val_loss: 2.6890 - val_policy_net_loss: 1.7975 - val_value_net_loss: 0.8916\n",
            "Epoch 210/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5541 - policy_net_loss: 1.6753 - value_net_loss: 0.8788 - val_loss: 2.6886 - val_policy_net_loss: 1.7960 - val_value_net_loss: 0.8926\n",
            "Epoch 211/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5611 - policy_net_loss: 1.6812 - value_net_loss: 0.8799 - val_loss: 2.6828 - val_policy_net_loss: 1.7910 - val_value_net_loss: 0.8918\n",
            "Epoch 212/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5545 - policy_net_loss: 1.6769 - value_net_loss: 0.8776 - val_loss: 2.6877 - val_policy_net_loss: 1.7966 - val_value_net_loss: 0.8910\n",
            "Epoch 213/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5599 - policy_net_loss: 1.6819 - value_net_loss: 0.8779 - val_loss: 2.6881 - val_policy_net_loss: 1.7935 - val_value_net_loss: 0.8946\n",
            "Epoch 214/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5565 - policy_net_loss: 1.6779 - value_net_loss: 0.8786 - val_loss: 2.6855 - val_policy_net_loss: 1.7934 - val_value_net_loss: 0.8921\n",
            "Epoch 215/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5571 - policy_net_loss: 1.6784 - value_net_loss: 0.8787 - val_loss: 2.6856 - val_policy_net_loss: 1.7939 - val_value_net_loss: 0.8917\n",
            "Epoch 216/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5583 - policy_net_loss: 1.6799 - value_net_loss: 0.8784 - val_loss: 2.6882 - val_policy_net_loss: 1.7961 - val_value_net_loss: 0.8922\n",
            "Epoch 217/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5558 - policy_net_loss: 1.6760 - value_net_loss: 0.8798 - val_loss: 2.6903 - val_policy_net_loss: 1.7941 - val_value_net_loss: 0.8961\n",
            "Epoch 218/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5554 - policy_net_loss: 1.6758 - value_net_loss: 0.8796 - val_loss: 2.6876 - val_policy_net_loss: 1.7971 - val_value_net_loss: 0.8905\n",
            "Epoch 219/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5597 - policy_net_loss: 1.6808 - value_net_loss: 0.8789 - val_loss: 2.6841 - val_policy_net_loss: 1.7918 - val_value_net_loss: 0.8923\n",
            "Epoch 220/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5629 - policy_net_loss: 1.6836 - value_net_loss: 0.8792 - val_loss: 2.6895 - val_policy_net_loss: 1.7987 - val_value_net_loss: 0.8908\n",
            "Epoch 221/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5632 - policy_net_loss: 1.6821 - value_net_loss: 0.8811 - val_loss: 2.6889 - val_policy_net_loss: 1.7961 - val_value_net_loss: 0.8928\n",
            "Epoch 222/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5560 - policy_net_loss: 1.6769 - value_net_loss: 0.8791 - val_loss: 2.6834 - val_policy_net_loss: 1.7917 - val_value_net_loss: 0.8917\n",
            "Epoch 223/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5658 - policy_net_loss: 1.6855 - value_net_loss: 0.8803 - val_loss: 2.6822 - val_policy_net_loss: 1.7927 - val_value_net_loss: 0.8895\n",
            "Epoch 224/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5537 - policy_net_loss: 1.6775 - value_net_loss: 0.8762 - val_loss: 2.6910 - val_policy_net_loss: 1.7963 - val_value_net_loss: 0.8947\n",
            "Epoch 225/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5524 - policy_net_loss: 1.6721 - value_net_loss: 0.8804 - val_loss: 2.6864 - val_policy_net_loss: 1.7957 - val_value_net_loss: 0.8907\n",
            "Epoch 226/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5541 - policy_net_loss: 1.6764 - value_net_loss: 0.8777 - val_loss: 2.6884 - val_policy_net_loss: 1.7953 - val_value_net_loss: 0.8932\n",
            "Epoch 227/400\n",
            "1200/1200 [==============================] - 8s 6ms/step - loss: 2.5592 - policy_net_loss: 1.6818 - value_net_loss: 0.8774 - val_loss: 2.6798 - val_policy_net_loss: 1.7875 - val_value_net_loss: 0.8923\n",
            "Epoch 228/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5527 - policy_net_loss: 1.6749 - value_net_loss: 0.8777 - val_loss: 2.6865 - val_policy_net_loss: 1.7939 - val_value_net_loss: 0.8925\n",
            "Epoch 229/400\n",
            "1200/1200 [==============================] - 8s 6ms/step - loss: 2.5488 - policy_net_loss: 1.6723 - value_net_loss: 0.8765 - val_loss: 2.6844 - val_policy_net_loss: 1.7917 - val_value_net_loss: 0.8927\n",
            "Epoch 230/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5564 - policy_net_loss: 1.6784 - value_net_loss: 0.8780 - val_loss: 2.6838 - val_policy_net_loss: 1.7924 - val_value_net_loss: 0.8914\n",
            "Epoch 231/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5511 - policy_net_loss: 1.6735 - value_net_loss: 0.8776 - val_loss: 2.6851 - val_policy_net_loss: 1.7924 - val_value_net_loss: 0.8926\n",
            "Epoch 232/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5554 - policy_net_loss: 1.6783 - value_net_loss: 0.8771 - val_loss: 2.6870 - val_policy_net_loss: 1.7933 - val_value_net_loss: 0.8938\n",
            "Epoch 233/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5491 - policy_net_loss: 1.6722 - value_net_loss: 0.8769 - val_loss: 2.6847 - val_policy_net_loss: 1.7920 - val_value_net_loss: 0.8927\n",
            "Epoch 234/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5535 - policy_net_loss: 1.6772 - value_net_loss: 0.8763 - val_loss: 2.6841 - val_policy_net_loss: 1.7911 - val_value_net_loss: 0.8930\n",
            "Epoch 235/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5489 - policy_net_loss: 1.6717 - value_net_loss: 0.8772 - val_loss: 2.6894 - val_policy_net_loss: 1.7954 - val_value_net_loss: 0.8940\n",
            "Epoch 236/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5457 - policy_net_loss: 1.6689 - value_net_loss: 0.8768 - val_loss: 2.6874 - val_policy_net_loss: 1.7927 - val_value_net_loss: 0.8947\n",
            "Epoch 237/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5470 - policy_net_loss: 1.6709 - value_net_loss: 0.8761 - val_loss: 2.6910 - val_policy_net_loss: 1.7989 - val_value_net_loss: 0.8921\n",
            "Epoch 238/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5485 - policy_net_loss: 1.6728 - value_net_loss: 0.8757 - val_loss: 2.6873 - val_policy_net_loss: 1.7936 - val_value_net_loss: 0.8937\n",
            "Epoch 239/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5444 - policy_net_loss: 1.6681 - value_net_loss: 0.8763 - val_loss: 2.6896 - val_policy_net_loss: 1.7958 - val_value_net_loss: 0.8938\n",
            "Epoch 240/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5488 - policy_net_loss: 1.6730 - value_net_loss: 0.8758 - val_loss: 2.6889 - val_policy_net_loss: 1.7977 - val_value_net_loss: 0.8912\n",
            "Epoch 241/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5478 - policy_net_loss: 1.6724 - value_net_loss: 0.8754 - val_loss: 2.6924 - val_policy_net_loss: 1.7979 - val_value_net_loss: 0.8945\n",
            "Epoch 242/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5480 - policy_net_loss: 1.6741 - value_net_loss: 0.8739 - val_loss: 2.6888 - val_policy_net_loss: 1.7943 - val_value_net_loss: 0.8946\n",
            "Epoch 243/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5442 - policy_net_loss: 1.6688 - value_net_loss: 0.8753 - val_loss: 2.6877 - val_policy_net_loss: 1.7941 - val_value_net_loss: 0.8936\n",
            "Epoch 244/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5466 - policy_net_loss: 1.6711 - value_net_loss: 0.8755 - val_loss: 2.6898 - val_policy_net_loss: 1.7976 - val_value_net_loss: 0.8922\n",
            "Epoch 245/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5426 - policy_net_loss: 1.6683 - value_net_loss: 0.8744 - val_loss: 2.6901 - val_policy_net_loss: 1.7972 - val_value_net_loss: 0.8929\n",
            "Epoch 246/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5500 - policy_net_loss: 1.6760 - value_net_loss: 0.8740 - val_loss: 2.6904 - val_policy_net_loss: 1.7964 - val_value_net_loss: 0.8940\n",
            "Epoch 247/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5477 - policy_net_loss: 1.6739 - value_net_loss: 0.8738 - val_loss: 2.6860 - val_policy_net_loss: 1.7923 - val_value_net_loss: 0.8936\n",
            "Epoch 248/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5412 - policy_net_loss: 1.6662 - value_net_loss: 0.8750 - val_loss: 2.6967 - val_policy_net_loss: 1.8040 - val_value_net_loss: 0.8928\n",
            "Epoch 249/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5495 - policy_net_loss: 1.6740 - value_net_loss: 0.8754 - val_loss: 2.6878 - val_policy_net_loss: 1.7961 - val_value_net_loss: 0.8917\n",
            "Epoch 250/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5451 - policy_net_loss: 1.6701 - value_net_loss: 0.8751 - val_loss: 2.6904 - val_policy_net_loss: 1.7989 - val_value_net_loss: 0.8914\n",
            "Epoch 251/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5462 - policy_net_loss: 1.6719 - value_net_loss: 0.8743 - val_loss: 2.6889 - val_policy_net_loss: 1.7961 - val_value_net_loss: 0.8928\n",
            "Epoch 252/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5466 - policy_net_loss: 1.6710 - value_net_loss: 0.8756 - val_loss: 2.6857 - val_policy_net_loss: 1.7935 - val_value_net_loss: 0.8922\n",
            "Epoch 253/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5455 - policy_net_loss: 1.6698 - value_net_loss: 0.8757 - val_loss: 2.6872 - val_policy_net_loss: 1.7958 - val_value_net_loss: 0.8914\n",
            "Epoch 254/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5421 - policy_net_loss: 1.6673 - value_net_loss: 0.8748 - val_loss: 2.6880 - val_policy_net_loss: 1.7954 - val_value_net_loss: 0.8926\n",
            "Epoch 255/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5408 - policy_net_loss: 1.6670 - value_net_loss: 0.8738 - val_loss: 2.6868 - val_policy_net_loss: 1.7944 - val_value_net_loss: 0.8924\n",
            "Epoch 256/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5389 - policy_net_loss: 1.6657 - value_net_loss: 0.8731 - val_loss: 2.6922 - val_policy_net_loss: 1.7996 - val_value_net_loss: 0.8926\n",
            "Epoch 257/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5495 - policy_net_loss: 1.6746 - value_net_loss: 0.8748 - val_loss: 2.6853 - val_policy_net_loss: 1.7940 - val_value_net_loss: 0.8913\n",
            "Epoch 258/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5418 - policy_net_loss: 1.6673 - value_net_loss: 0.8745 - val_loss: 2.6897 - val_policy_net_loss: 1.7969 - val_value_net_loss: 0.8929\n",
            "Epoch 259/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5409 - policy_net_loss: 1.6669 - value_net_loss: 0.8740 - val_loss: 2.6883 - val_policy_net_loss: 1.7962 - val_value_net_loss: 0.8921\n",
            "Epoch 260/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5426 - policy_net_loss: 1.6692 - value_net_loss: 0.8734 - val_loss: 2.6909 - val_policy_net_loss: 1.7972 - val_value_net_loss: 0.8937\n",
            "Epoch 261/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5416 - policy_net_loss: 1.6687 - value_net_loss: 0.8729 - val_loss: 2.6923 - val_policy_net_loss: 1.7990 - val_value_net_loss: 0.8933\n",
            "Epoch 262/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5411 - policy_net_loss: 1.6679 - value_net_loss: 0.8731 - val_loss: 2.6937 - val_policy_net_loss: 1.7998 - val_value_net_loss: 0.8939\n",
            "Epoch 263/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5428 - policy_net_loss: 1.6681 - value_net_loss: 0.8747 - val_loss: 2.6839 - val_policy_net_loss: 1.7945 - val_value_net_loss: 0.8894\n",
            "Epoch 264/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5417 - policy_net_loss: 1.6677 - value_net_loss: 0.8739 - val_loss: 2.6872 - val_policy_net_loss: 1.7958 - val_value_net_loss: 0.8914\n",
            "Epoch 265/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5409 - policy_net_loss: 1.6682 - value_net_loss: 0.8727 - val_loss: 2.6829 - val_policy_net_loss: 1.7916 - val_value_net_loss: 0.8913\n",
            "Epoch 266/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5391 - policy_net_loss: 1.6669 - value_net_loss: 0.8722 - val_loss: 2.6905 - val_policy_net_loss: 1.7990 - val_value_net_loss: 0.8915\n",
            "Epoch 267/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5437 - policy_net_loss: 1.6712 - value_net_loss: 0.8726 - val_loss: 2.6890 - val_policy_net_loss: 1.7978 - val_value_net_loss: 0.8912\n",
            "Epoch 268/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5464 - policy_net_loss: 1.6720 - value_net_loss: 0.8744 - val_loss: 2.6896 - val_policy_net_loss: 1.7940 - val_value_net_loss: 0.8956\n",
            "Epoch 269/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5404 - policy_net_loss: 1.6675 - value_net_loss: 0.8730 - val_loss: 2.6910 - val_policy_net_loss: 1.7956 - val_value_net_loss: 0.8954\n",
            "Epoch 270/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5430 - policy_net_loss: 1.6692 - value_net_loss: 0.8738 - val_loss: 2.6900 - val_policy_net_loss: 1.7974 - val_value_net_loss: 0.8926\n",
            "Epoch 271/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5356 - policy_net_loss: 1.6638 - value_net_loss: 0.8719 - val_loss: 2.6896 - val_policy_net_loss: 1.7963 - val_value_net_loss: 0.8933\n",
            "Epoch 272/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5389 - policy_net_loss: 1.6671 - value_net_loss: 0.8718 - val_loss: 2.6908 - val_policy_net_loss: 1.7973 - val_value_net_loss: 0.8935\n",
            "Epoch 273/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5333 - policy_net_loss: 1.6624 - value_net_loss: 0.8709 - val_loss: 2.6913 - val_policy_net_loss: 1.7981 - val_value_net_loss: 0.8932\n",
            "Epoch 274/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5431 - policy_net_loss: 1.6707 - value_net_loss: 0.8724 - val_loss: 2.6859 - val_policy_net_loss: 1.7954 - val_value_net_loss: 0.8905\n",
            "Epoch 275/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5334 - policy_net_loss: 1.6622 - value_net_loss: 0.8712 - val_loss: 2.6944 - val_policy_net_loss: 1.8015 - val_value_net_loss: 0.8929\n",
            "Epoch 276/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5406 - policy_net_loss: 1.6689 - value_net_loss: 0.8718 - val_loss: 2.6977 - val_policy_net_loss: 1.8015 - val_value_net_loss: 0.8962\n",
            "Epoch 277/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5420 - policy_net_loss: 1.6680 - value_net_loss: 0.8740 - val_loss: 2.6956 - val_policy_net_loss: 1.8016 - val_value_net_loss: 0.8939\n",
            "Epoch 278/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5380 - policy_net_loss: 1.6636 - value_net_loss: 0.8745 - val_loss: 2.6905 - val_policy_net_loss: 1.7998 - val_value_net_loss: 0.8907\n",
            "Epoch 279/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5379 - policy_net_loss: 1.6663 - value_net_loss: 0.8716 - val_loss: 2.6940 - val_policy_net_loss: 1.7999 - val_value_net_loss: 0.8941\n",
            "Epoch 280/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5381 - policy_net_loss: 1.6653 - value_net_loss: 0.8729 - val_loss: 2.6960 - val_policy_net_loss: 1.8033 - val_value_net_loss: 0.8927\n",
            "Epoch 281/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5351 - policy_net_loss: 1.6633 - value_net_loss: 0.8718 - val_loss: 2.6947 - val_policy_net_loss: 1.8006 - val_value_net_loss: 0.8941\n",
            "Epoch 282/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5370 - policy_net_loss: 1.6628 - value_net_loss: 0.8742 - val_loss: 2.6955 - val_policy_net_loss: 1.8021 - val_value_net_loss: 0.8933\n",
            "Epoch 283/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5371 - policy_net_loss: 1.6649 - value_net_loss: 0.8722 - val_loss: 2.6944 - val_policy_net_loss: 1.7997 - val_value_net_loss: 0.8947\n",
            "Epoch 284/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5398 - policy_net_loss: 1.6663 - value_net_loss: 0.8734 - val_loss: 2.6895 - val_policy_net_loss: 1.7973 - val_value_net_loss: 0.8923\n",
            "Epoch 285/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5369 - policy_net_loss: 1.6657 - value_net_loss: 0.8712 - val_loss: 2.6933 - val_policy_net_loss: 1.7998 - val_value_net_loss: 0.8936\n",
            "Epoch 286/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5361 - policy_net_loss: 1.6654 - value_net_loss: 0.8707 - val_loss: 2.6918 - val_policy_net_loss: 1.7999 - val_value_net_loss: 0.8919\n",
            "Epoch 287/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5364 - policy_net_loss: 1.6640 - value_net_loss: 0.8725 - val_loss: 2.6885 - val_policy_net_loss: 1.7967 - val_value_net_loss: 0.8917\n",
            "Epoch 288/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5347 - policy_net_loss: 1.6661 - value_net_loss: 0.8685 - val_loss: 2.6924 - val_policy_net_loss: 1.7986 - val_value_net_loss: 0.8939\n",
            "Epoch 289/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5308 - policy_net_loss: 1.6587 - value_net_loss: 0.8721 - val_loss: 2.6930 - val_policy_net_loss: 1.8010 - val_value_net_loss: 0.8920\n",
            "Epoch 290/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5323 - policy_net_loss: 1.6612 - value_net_loss: 0.8711 - val_loss: 2.6988 - val_policy_net_loss: 1.8038 - val_value_net_loss: 0.8950\n",
            "Epoch 291/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5398 - policy_net_loss: 1.6688 - value_net_loss: 0.8710 - val_loss: 2.6904 - val_policy_net_loss: 1.7935 - val_value_net_loss: 0.8969\n",
            "Epoch 292/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5363 - policy_net_loss: 1.6658 - value_net_loss: 0.8705 - val_loss: 2.6916 - val_policy_net_loss: 1.7985 - val_value_net_loss: 0.8931\n",
            "Epoch 293/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5300 - policy_net_loss: 1.6607 - value_net_loss: 0.8693 - val_loss: 2.6949 - val_policy_net_loss: 1.8008 - val_value_net_loss: 0.8941\n",
            "Epoch 294/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5273 - policy_net_loss: 1.6578 - value_net_loss: 0.8695 - val_loss: 2.6905 - val_policy_net_loss: 1.7975 - val_value_net_loss: 0.8930\n",
            "Epoch 295/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5354 - policy_net_loss: 1.6640 - value_net_loss: 0.8714 - val_loss: 2.6929 - val_policy_net_loss: 1.7997 - val_value_net_loss: 0.8932\n",
            "Epoch 296/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5294 - policy_net_loss: 1.6581 - value_net_loss: 0.8714 - val_loss: 2.6868 - val_policy_net_loss: 1.7930 - val_value_net_loss: 0.8938\n",
            "Epoch 297/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5312 - policy_net_loss: 1.6619 - value_net_loss: 0.8694 - val_loss: 2.6949 - val_policy_net_loss: 1.7990 - val_value_net_loss: 0.8959\n",
            "Epoch 298/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5313 - policy_net_loss: 1.6596 - value_net_loss: 0.8718 - val_loss: 2.6940 - val_policy_net_loss: 1.8027 - val_value_net_loss: 0.8913\n",
            "Epoch 299/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5279 - policy_net_loss: 1.6596 - value_net_loss: 0.8683 - val_loss: 2.6989 - val_policy_net_loss: 1.8027 - val_value_net_loss: 0.8962\n",
            "Epoch 300/400\n",
            "1200/1200 [==============================] - 9s 8ms/step - loss: 2.5303 - policy_net_loss: 1.6602 - value_net_loss: 0.8701 - val_loss: 2.6954 - val_policy_net_loss: 1.8017 - val_value_net_loss: 0.8937\n",
            "Epoch 301/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5335 - policy_net_loss: 1.6659 - value_net_loss: 0.8676 - val_loss: 2.6941 - val_policy_net_loss: 1.8009 - val_value_net_loss: 0.8933\n",
            "Epoch 302/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5357 - policy_net_loss: 1.6637 - value_net_loss: 0.8720 - val_loss: 2.6888 - val_policy_net_loss: 1.7965 - val_value_net_loss: 0.8923\n",
            "Epoch 303/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5297 - policy_net_loss: 1.6586 - value_net_loss: 0.8710 - val_loss: 2.6961 - val_policy_net_loss: 1.8037 - val_value_net_loss: 0.8924\n",
            "Epoch 304/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5223 - policy_net_loss: 1.6552 - value_net_loss: 0.8671 - val_loss: 2.6983 - val_policy_net_loss: 1.8041 - val_value_net_loss: 0.8941\n",
            "Epoch 305/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5310 - policy_net_loss: 1.6595 - value_net_loss: 0.8715 - val_loss: 2.6929 - val_policy_net_loss: 1.7994 - val_value_net_loss: 0.8935\n",
            "Epoch 306/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5342 - policy_net_loss: 1.6647 - value_net_loss: 0.8695 - val_loss: 2.6924 - val_policy_net_loss: 1.7990 - val_value_net_loss: 0.8934\n",
            "Epoch 307/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5249 - policy_net_loss: 1.6540 - value_net_loss: 0.8710 - val_loss: 2.7001 - val_policy_net_loss: 1.8048 - val_value_net_loss: 0.8953\n",
            "Epoch 308/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5297 - policy_net_loss: 1.6602 - value_net_loss: 0.8695 - val_loss: 2.6938 - val_policy_net_loss: 1.8013 - val_value_net_loss: 0.8925\n",
            "Epoch 309/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5290 - policy_net_loss: 1.6594 - value_net_loss: 0.8696 - val_loss: 2.6894 - val_policy_net_loss: 1.7976 - val_value_net_loss: 0.8919\n",
            "Epoch 310/400\n",
            "1200/1200 [==============================] - 9s 7ms/step - loss: 2.5297 - policy_net_loss: 1.6601 - value_net_loss: 0.8696 - val_loss: 2.6937 - val_policy_net_loss: 1.8003 - val_value_net_loss: 0.8935\n",
            "Epoch 311/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5282 - policy_net_loss: 1.6591 - value_net_loss: 0.8690 - val_loss: 2.7015 - val_policy_net_loss: 1.8062 - val_value_net_loss: 0.8953\n",
            "Epoch 312/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5278 - policy_net_loss: 1.6573 - value_net_loss: 0.8705 - val_loss: 2.6975 - val_policy_net_loss: 1.8027 - val_value_net_loss: 0.8949\n",
            "Epoch 313/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5260 - policy_net_loss: 1.6587 - value_net_loss: 0.8673 - val_loss: 2.7007 - val_policy_net_loss: 1.8057 - val_value_net_loss: 0.8950\n",
            "Epoch 314/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5307 - policy_net_loss: 1.6604 - value_net_loss: 0.8703 - val_loss: 2.6960 - val_policy_net_loss: 1.8022 - val_value_net_loss: 0.8938\n",
            "Epoch 315/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5331 - policy_net_loss: 1.6621 - value_net_loss: 0.8710 - val_loss: 2.6965 - val_policy_net_loss: 1.8036 - val_value_net_loss: 0.8928\n",
            "Epoch 316/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5209 - policy_net_loss: 1.6530 - value_net_loss: 0.8679 - val_loss: 2.7019 - val_policy_net_loss: 1.8089 - val_value_net_loss: 0.8930\n",
            "Epoch 317/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5249 - policy_net_loss: 1.6561 - value_net_loss: 0.8687 - val_loss: 2.7009 - val_policy_net_loss: 1.8088 - val_value_net_loss: 0.8921\n",
            "Epoch 318/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5259 - policy_net_loss: 1.6575 - value_net_loss: 0.8684 - val_loss: 2.6986 - val_policy_net_loss: 1.8054 - val_value_net_loss: 0.8932\n",
            "Epoch 319/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5308 - policy_net_loss: 1.6600 - value_net_loss: 0.8708 - val_loss: 2.6990 - val_policy_net_loss: 1.8062 - val_value_net_loss: 0.8928\n",
            "Epoch 320/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5301 - policy_net_loss: 1.6596 - value_net_loss: 0.8705 - val_loss: 2.6974 - val_policy_net_loss: 1.8038 - val_value_net_loss: 0.8937\n",
            "Epoch 321/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5244 - policy_net_loss: 1.6564 - value_net_loss: 0.8680 - val_loss: 2.6999 - val_policy_net_loss: 1.8067 - val_value_net_loss: 0.8932\n",
            "Epoch 322/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5238 - policy_net_loss: 1.6564 - value_net_loss: 0.8673 - val_loss: 2.6971 - val_policy_net_loss: 1.8046 - val_value_net_loss: 0.8925\n",
            "Epoch 323/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5284 - policy_net_loss: 1.6591 - value_net_loss: 0.8693 - val_loss: 2.7000 - val_policy_net_loss: 1.8030 - val_value_net_loss: 0.8970\n",
            "Epoch 324/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5282 - policy_net_loss: 1.6593 - value_net_loss: 0.8689 - val_loss: 2.6959 - val_policy_net_loss: 1.8034 - val_value_net_loss: 0.8925\n",
            "Epoch 325/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5223 - policy_net_loss: 1.6559 - value_net_loss: 0.8664 - val_loss: 2.6974 - val_policy_net_loss: 1.8009 - val_value_net_loss: 0.8965\n",
            "Epoch 326/400\n",
            "1200/1200 [==============================] - 9s 7ms/step - loss: 2.5238 - policy_net_loss: 1.6538 - value_net_loss: 0.8699 - val_loss: 2.6977 - val_policy_net_loss: 1.8053 - val_value_net_loss: 0.8925\n",
            "Epoch 327/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5201 - policy_net_loss: 1.6514 - value_net_loss: 0.8687 - val_loss: 2.7011 - val_policy_net_loss: 1.8035 - val_value_net_loss: 0.8976\n",
            "Epoch 328/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5295 - policy_net_loss: 1.6628 - value_net_loss: 0.8667 - val_loss: 2.7022 - val_policy_net_loss: 1.8074 - val_value_net_loss: 0.8948\n",
            "Epoch 329/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5263 - policy_net_loss: 1.6570 - value_net_loss: 0.8693 - val_loss: 2.6979 - val_policy_net_loss: 1.8036 - val_value_net_loss: 0.8943\n",
            "Epoch 330/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5213 - policy_net_loss: 1.6545 - value_net_loss: 0.8668 - val_loss: 2.7040 - val_policy_net_loss: 1.8106 - val_value_net_loss: 0.8934\n",
            "Epoch 331/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5209 - policy_net_loss: 1.6541 - value_net_loss: 0.8669 - val_loss: 2.7020 - val_policy_net_loss: 1.8092 - val_value_net_loss: 0.8928\n",
            "Epoch 332/400\n",
            "1200/1200 [==============================] - 9s 8ms/step - loss: 2.5240 - policy_net_loss: 1.6574 - value_net_loss: 0.8666 - val_loss: 2.6972 - val_policy_net_loss: 1.8034 - val_value_net_loss: 0.8939\n",
            "Epoch 333/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5244 - policy_net_loss: 1.6567 - value_net_loss: 0.8678 - val_loss: 2.6958 - val_policy_net_loss: 1.8026 - val_value_net_loss: 0.8932\n",
            "Epoch 334/400\n",
            "1200/1200 [==============================] - 9s 7ms/step - loss: 2.5228 - policy_net_loss: 1.6555 - value_net_loss: 0.8673 - val_loss: 2.7015 - val_policy_net_loss: 1.8068 - val_value_net_loss: 0.8947\n",
            "Epoch 335/400\n",
            "1200/1200 [==============================] - 9s 7ms/step - loss: 2.5249 - policy_net_loss: 1.6579 - value_net_loss: 0.8670 - val_loss: 2.7048 - val_policy_net_loss: 1.8101 - val_value_net_loss: 0.8947\n",
            "Epoch 336/400\n",
            "1200/1200 [==============================] - 9s 7ms/step - loss: 2.5222 - policy_net_loss: 1.6550 - value_net_loss: 0.8673 - val_loss: 2.6987 - val_policy_net_loss: 1.8035 - val_value_net_loss: 0.8952\n",
            "Epoch 337/400\n",
            "1200/1200 [==============================] - 9s 8ms/step - loss: 2.5244 - policy_net_loss: 1.6567 - value_net_loss: 0.8678 - val_loss: 2.6960 - val_policy_net_loss: 1.8026 - val_value_net_loss: 0.8934\n",
            "Epoch 338/400\n",
            "1200/1200 [==============================] - 9s 7ms/step - loss: 2.5269 - policy_net_loss: 1.6596 - value_net_loss: 0.8673 - val_loss: 2.7009 - val_policy_net_loss: 1.8046 - val_value_net_loss: 0.8962\n",
            "Epoch 339/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5193 - policy_net_loss: 1.6541 - value_net_loss: 0.8652 - val_loss: 2.7031 - val_policy_net_loss: 1.8083 - val_value_net_loss: 0.8948\n",
            "Epoch 340/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5221 - policy_net_loss: 1.6541 - value_net_loss: 0.8680 - val_loss: 2.7010 - val_policy_net_loss: 1.8078 - val_value_net_loss: 0.8932\n",
            "Epoch 341/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5180 - policy_net_loss: 1.6526 - value_net_loss: 0.8654 - val_loss: 2.7016 - val_policy_net_loss: 1.8094 - val_value_net_loss: 0.8922\n",
            "Epoch 342/400\n",
            "1200/1200 [==============================] - 9s 7ms/step - loss: 2.5218 - policy_net_loss: 1.6563 - value_net_loss: 0.8655 - val_loss: 2.6969 - val_policy_net_loss: 1.8036 - val_value_net_loss: 0.8934\n",
            "Epoch 343/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5193 - policy_net_loss: 1.6521 - value_net_loss: 0.8672 - val_loss: 2.7022 - val_policy_net_loss: 1.8070 - val_value_net_loss: 0.8952\n",
            "Epoch 344/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5195 - policy_net_loss: 1.6525 - value_net_loss: 0.8671 - val_loss: 2.6978 - val_policy_net_loss: 1.8058 - val_value_net_loss: 0.8920\n",
            "Epoch 345/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5187 - policy_net_loss: 1.6527 - value_net_loss: 0.8660 - val_loss: 2.6987 - val_policy_net_loss: 1.8049 - val_value_net_loss: 0.8938\n",
            "Epoch 346/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5212 - policy_net_loss: 1.6566 - value_net_loss: 0.8646 - val_loss: 2.7033 - val_policy_net_loss: 1.8071 - val_value_net_loss: 0.8962\n",
            "Epoch 347/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5220 - policy_net_loss: 1.6567 - value_net_loss: 0.8653 - val_loss: 2.7029 - val_policy_net_loss: 1.8092 - val_value_net_loss: 0.8937\n",
            "Epoch 348/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5198 - policy_net_loss: 1.6545 - value_net_loss: 0.8653 - val_loss: 2.7000 - val_policy_net_loss: 1.8056 - val_value_net_loss: 0.8945\n",
            "Epoch 349/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5250 - policy_net_loss: 1.6599 - value_net_loss: 0.8651 - val_loss: 2.6895 - val_policy_net_loss: 1.7970 - val_value_net_loss: 0.8925\n",
            "Epoch 350/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5184 - policy_net_loss: 1.6528 - value_net_loss: 0.8656 - val_loss: 2.6991 - val_policy_net_loss: 1.8050 - val_value_net_loss: 0.8941\n",
            "Epoch 351/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5217 - policy_net_loss: 1.6565 - value_net_loss: 0.8652 - val_loss: 2.6973 - val_policy_net_loss: 1.8002 - val_value_net_loss: 0.8971\n",
            "Epoch 352/400\n",
            "1200/1200 [==============================] - 8s 7ms/step - loss: 2.5175 - policy_net_loss: 1.6521 - value_net_loss: 0.8655 - val_loss: 2.6963 - val_policy_net_loss: 1.8031 - val_value_net_loss: 0.8933\n",
            "Epoch 353/400\n",
            "1200/1200 [==============================] - 9s 7ms/step - loss: 2.5136 - policy_net_loss: 1.6493 - value_net_loss: 0.8643 - val_loss: 2.7022 - val_policy_net_loss: 1.8072 - val_value_net_loss: 0.8950\n",
            "Epoch 354/400\n",
            "1200/1200 [==============================] - 9s 7ms/step - loss: 2.5165 - policy_net_loss: 1.6514 - value_net_loss: 0.8651 - val_loss: 2.6994 - val_policy_net_loss: 1.8050 - val_value_net_loss: 0.8944\n",
            "Epoch 355/400\n",
            "1200/1200 [==============================] - 9s 7ms/step - loss: 2.5170 - policy_net_loss: 1.6521 - value_net_loss: 0.8650 - val_loss: 2.6993 - val_policy_net_loss: 1.8053 - val_value_net_loss: 0.8940\n",
            "Epoch 356/400\n",
            "1200/1200 [==============================] - 9s 7ms/step - loss: 2.5182 - policy_net_loss: 1.6529 - value_net_loss: 0.8653 - val_loss: 2.6993 - val_policy_net_loss: 1.8041 - val_value_net_loss: 0.8951\n",
            "Epoch 357/400\n",
            "1200/1200 [==============================] - 9s 7ms/step - loss: 2.5214 - policy_net_loss: 1.6572 - value_net_loss: 0.8642 - val_loss: 2.7039 - val_policy_net_loss: 1.8079 - val_value_net_loss: 0.8961\n",
            "Epoch 358/400\n",
            "1200/1200 [==============================] - 9s 7ms/step - loss: 2.5165 - policy_net_loss: 1.6498 - value_net_loss: 0.8667 - val_loss: 2.7004 - val_policy_net_loss: 1.8058 - val_value_net_loss: 0.8946\n",
            "Epoch 359/400\n",
            "1200/1200 [==============================] - 9s 8ms/step - loss: 2.5161 - policy_net_loss: 1.6504 - value_net_loss: 0.8657 - val_loss: 2.6994 - val_policy_net_loss: 1.8038 - val_value_net_loss: 0.8957\n",
            "Epoch 360/400\n",
            "1200/1200 [==============================] - 9s 7ms/step - loss: 2.5188 - policy_net_loss: 1.6551 - value_net_loss: 0.8636 - val_loss: 2.7019 - val_policy_net_loss: 1.8067 - val_value_net_loss: 0.8952\n",
            "Epoch 361/400\n",
            "1200/1200 [==============================] - 9s 7ms/step - loss: 2.5193 - policy_net_loss: 1.6524 - value_net_loss: 0.8668 - val_loss: 2.7032 - val_policy_net_loss: 1.8052 - val_value_net_loss: 0.8979\n",
            "Epoch 362/400\n",
            "1200/1200 [==============================] - 9s 7ms/step - loss: 2.5213 - policy_net_loss: 1.6549 - value_net_loss: 0.8664 - val_loss: 2.6976 - val_policy_net_loss: 1.8044 - val_value_net_loss: 0.8933\n",
            "Epoch 363/400\n",
            "1200/1200 [==============================] - 9s 7ms/step - loss: 2.5168 - policy_net_loss: 1.6532 - value_net_loss: 0.8636 - val_loss: 2.6995 - val_policy_net_loss: 1.8049 - val_value_net_loss: 0.8946\n",
            "Epoch 364/400\n",
            "1200/1200 [==============================] - 9s 7ms/step - loss: 2.5168 - policy_net_loss: 1.6511 - value_net_loss: 0.8657 - val_loss: 2.7049 - val_policy_net_loss: 1.8090 - val_value_net_loss: 0.8959\n",
            "Epoch 365/400\n",
            "1200/1200 [==============================] - 9s 7ms/step - loss: 2.5180 - policy_net_loss: 1.6517 - value_net_loss: 0.8663 - val_loss: 2.6941 - val_policy_net_loss: 1.8030 - val_value_net_loss: 0.8912\n",
            "Epoch 366/400\n",
            "1200/1200 [==============================] - 9s 7ms/step - loss: 2.5156 - policy_net_loss: 1.6502 - value_net_loss: 0.8654 - val_loss: 2.6969 - val_policy_net_loss: 1.8049 - val_value_net_loss: 0.8920\n",
            "Epoch 367/400\n",
            "1200/1200 [==============================] - 9s 7ms/step - loss: 2.5108 - policy_net_loss: 1.6472 - value_net_loss: 0.8636 - val_loss: 2.7038 - val_policy_net_loss: 1.8101 - val_value_net_loss: 0.8937\n",
            "Epoch 368/400\n",
            "1200/1200 [==============================] - 9s 7ms/step - loss: 2.5136 - policy_net_loss: 1.6499 - value_net_loss: 0.8638 - val_loss: 2.7040 - val_policy_net_loss: 1.8075 - val_value_net_loss: 0.8964\n",
            "Epoch 369/400\n",
            "1200/1200 [==============================] - 9s 7ms/step - loss: 2.5146 - policy_net_loss: 1.6507 - value_net_loss: 0.8640 - val_loss: 2.7026 - val_policy_net_loss: 1.8072 - val_value_net_loss: 0.8954\n",
            "Epoch 370/400\n",
            "1200/1200 [==============================] - 9s 7ms/step - loss: 2.5205 - policy_net_loss: 1.6554 - value_net_loss: 0.8651 - val_loss: 2.7006 - val_policy_net_loss: 1.8059 - val_value_net_loss: 0.8947\n",
            "Epoch 371/400\n",
            "1200/1200 [==============================] - 9s 7ms/step - loss: 2.5153 - policy_net_loss: 1.6504 - value_net_loss: 0.8648 - val_loss: 2.6989 - val_policy_net_loss: 1.8059 - val_value_net_loss: 0.8929\n",
            "Epoch 372/400\n",
            "1200/1200 [==============================] - 9s 7ms/step - loss: 2.5127 - policy_net_loss: 1.6471 - value_net_loss: 0.8656 - val_loss: 2.7050 - val_policy_net_loss: 1.8082 - val_value_net_loss: 0.8968\n",
            "Epoch 373/400\n",
            "1200/1200 [==============================] - 9s 7ms/step - loss: 2.5147 - policy_net_loss: 1.6496 - value_net_loss: 0.8652 - val_loss: 2.7021 - val_policy_net_loss: 1.8077 - val_value_net_loss: 0.8944\n",
            "Epoch 374/400\n",
            "1200/1200 [==============================] - 9s 7ms/step - loss: 2.5147 - policy_net_loss: 1.6495 - value_net_loss: 0.8652 - val_loss: 2.7032 - val_policy_net_loss: 1.8072 - val_value_net_loss: 0.8960\n",
            "Epoch 375/400\n",
            "1200/1200 [==============================] - 9s 7ms/step - loss: 2.5171 - policy_net_loss: 1.6522 - value_net_loss: 0.8649 - val_loss: 2.6957 - val_policy_net_loss: 1.8006 - val_value_net_loss: 0.8951\n",
            "Epoch 376/400\n",
            "1200/1200 [==============================] - 9s 7ms/step - loss: 2.5157 - policy_net_loss: 1.6507 - value_net_loss: 0.8650 - val_loss: 2.7012 - val_policy_net_loss: 1.8081 - val_value_net_loss: 0.8931\n",
            "Epoch 377/400\n",
            "1200/1200 [==============================] - 9s 7ms/step - loss: 2.5139 - policy_net_loss: 1.6508 - value_net_loss: 0.8631 - val_loss: 2.6980 - val_policy_net_loss: 1.8052 - val_value_net_loss: 0.8928\n",
            "Epoch 378/400\n",
            "1200/1200 [==============================] - 9s 7ms/step - loss: 2.5152 - policy_net_loss: 1.6504 - value_net_loss: 0.8649 - val_loss: 2.6984 - val_policy_net_loss: 1.8044 - val_value_net_loss: 0.8940\n",
            "Epoch 379/400\n",
            "1200/1200 [==============================] - 9s 7ms/step - loss: 2.5208 - policy_net_loss: 1.6570 - value_net_loss: 0.8638 - val_loss: 2.7038 - val_policy_net_loss: 1.8070 - val_value_net_loss: 0.8967\n",
            "Epoch 380/400\n",
            "1200/1200 [==============================] - 9s 7ms/step - loss: 2.5143 - policy_net_loss: 1.6517 - value_net_loss: 0.8626 - val_loss: 2.7035 - val_policy_net_loss: 1.8062 - val_value_net_loss: 0.8973\n",
            "Epoch 381/400\n",
            "1200/1200 [==============================] - 9s 7ms/step - loss: 2.5128 - policy_net_loss: 1.6496 - value_net_loss: 0.8632 - val_loss: 2.6968 - val_policy_net_loss: 1.7995 - val_value_net_loss: 0.8974\n",
            "Epoch 382/400\n",
            "1200/1200 [==============================] - 9s 7ms/step - loss: 2.5157 - policy_net_loss: 1.6524 - value_net_loss: 0.8633 - val_loss: 2.6996 - val_policy_net_loss: 1.8044 - val_value_net_loss: 0.8952\n",
            "Epoch 383/400\n",
            "1200/1200 [==============================] - 9s 8ms/step - loss: 2.5116 - policy_net_loss: 1.6473 - value_net_loss: 0.8644 - val_loss: 2.6977 - val_policy_net_loss: 1.8021 - val_value_net_loss: 0.8956\n",
            "Epoch 384/400\n",
            "1200/1200 [==============================] - 9s 7ms/step - loss: 2.5127 - policy_net_loss: 1.6479 - value_net_loss: 0.8648 - val_loss: 2.7037 - val_policy_net_loss: 1.8087 - val_value_net_loss: 0.8950\n",
            "Epoch 385/400\n",
            "1200/1200 [==============================] - 9s 7ms/step - loss: 2.5098 - policy_net_loss: 1.6469 - value_net_loss: 0.8629 - val_loss: 2.7048 - val_policy_net_loss: 1.8107 - val_value_net_loss: 0.8940\n",
            "Epoch 386/400\n",
            "1200/1200 [==============================] - 9s 8ms/step - loss: 2.5160 - policy_net_loss: 1.6516 - value_net_loss: 0.8644 - val_loss: 2.6968 - val_policy_net_loss: 1.8024 - val_value_net_loss: 0.8944\n",
            "Epoch 387/400\n",
            "1200/1200 [==============================] - 9s 7ms/step - loss: 2.5093 - policy_net_loss: 1.6467 - value_net_loss: 0.8626 - val_loss: 2.6974 - val_policy_net_loss: 1.8021 - val_value_net_loss: 0.8953\n",
            "Epoch 388/400\n",
            "1200/1200 [==============================] - 9s 7ms/step - loss: 2.5102 - policy_net_loss: 1.6477 - value_net_loss: 0.8625 - val_loss: 2.6965 - val_policy_net_loss: 1.8044 - val_value_net_loss: 0.8922\n",
            "Epoch 389/400\n",
            "1200/1200 [==============================] - 9s 8ms/step - loss: 2.5183 - policy_net_loss: 1.6528 - value_net_loss: 0.8655 - val_loss: 2.7036 - val_policy_net_loss: 1.8103 - val_value_net_loss: 0.8934\n",
            "Epoch 390/400\n",
            "1200/1200 [==============================] - 9s 7ms/step - loss: 2.5112 - policy_net_loss: 1.6477 - value_net_loss: 0.8635 - val_loss: 2.6973 - val_policy_net_loss: 1.8053 - val_value_net_loss: 0.8919\n",
            "Epoch 391/400\n",
            "1200/1200 [==============================] - 9s 7ms/step - loss: 2.5110 - policy_net_loss: 1.6473 - value_net_loss: 0.8638 - val_loss: 2.7022 - val_policy_net_loss: 1.8089 - val_value_net_loss: 0.8932\n",
            "Epoch 392/400\n",
            "1200/1200 [==============================] - 9s 7ms/step - loss: 2.5149 - policy_net_loss: 1.6493 - value_net_loss: 0.8656 - val_loss: 2.6956 - val_policy_net_loss: 1.8038 - val_value_net_loss: 0.8918\n",
            "Epoch 393/400\n",
            "1200/1200 [==============================] - 9s 7ms/step - loss: 2.5112 - policy_net_loss: 1.6502 - value_net_loss: 0.8611 - val_loss: 2.7002 - val_policy_net_loss: 1.8055 - val_value_net_loss: 0.8947\n",
            "Epoch 394/400\n",
            "1200/1200 [==============================] - 9s 7ms/step - loss: 2.5072 - policy_net_loss: 1.6446 - value_net_loss: 0.8625 - val_loss: 2.7036 - val_policy_net_loss: 1.8108 - val_value_net_loss: 0.8927\n",
            "Epoch 395/400\n",
            "1200/1200 [==============================] - 9s 7ms/step - loss: 2.5137 - policy_net_loss: 1.6493 - value_net_loss: 0.8644 - val_loss: 2.7069 - val_policy_net_loss: 1.8117 - val_value_net_loss: 0.8952\n",
            "Epoch 396/400\n",
            "1200/1200 [==============================] - 9s 7ms/step - loss: 2.5156 - policy_net_loss: 1.6510 - value_net_loss: 0.8646 - val_loss: 2.7023 - val_policy_net_loss: 1.8080 - val_value_net_loss: 0.8943\n",
            "Epoch 397/400\n",
            "1200/1200 [==============================] - 9s 7ms/step - loss: 2.5119 - policy_net_loss: 1.6477 - value_net_loss: 0.8642 - val_loss: 2.7027 - val_policy_net_loss: 1.8104 - val_value_net_loss: 0.8923\n",
            "Epoch 398/400\n",
            "1200/1200 [==============================] - 9s 7ms/step - loss: 2.5117 - policy_net_loss: 1.6474 - value_net_loss: 0.8643 - val_loss: 2.7093 - val_policy_net_loss: 1.8146 - val_value_net_loss: 0.8946\n",
            "Epoch 399/400\n",
            "1200/1200 [==============================] - 9s 7ms/step - loss: 2.5146 - policy_net_loss: 1.6512 - value_net_loss: 0.8634 - val_loss: 2.7021 - val_policy_net_loss: 1.8084 - val_value_net_loss: 0.8937\n",
            "Epoch 400/400\n",
            "1200/1200 [==============================] - 9s 7ms/step - loss: 2.5125 - policy_net_loss: 1.6503 - value_net_loss: 0.8622 - val_loss: 2.7032 - val_policy_net_loss: 1.8081 - val_value_net_loss: 0.8951\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uszyoFSFHkLM"
      },
      "source": [
        "import pickle\n",
        "with open('trainHistoryDict_b', 'wb') as file_pi:\n",
        "    pickle.dump(history.history, file_pi)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYJwP99CKYvf"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# convert the history.history dict to a pandas DataFrame:     \n",
        "hist_df = pd.DataFrame(history.history) \n",
        "\n",
        "# save to json:  \n",
        "hist_json_file = 'history_b.json' \n",
        "with open(hist_json_file, mode='w') as f:\n",
        "    hist_df.to_json(f)\n",
        "\n",
        "# or save to csv: \n",
        "hist_csv_file = 'history_b.csv'\n",
        "with open(hist_csv_file, mode='w') as f:\n",
        "    hist_df.to_csv(f)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKgyC5K_4O0d"
      },
      "source": [
        "### Evaluate the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNR1yN-7cwpa"
      },
      "source": [
        "MEU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2OJnlOSPhzM"
      },
      "source": [
        "Op1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "HDJ7YVo-cx6o",
        "outputId": "cb6733b9-ff68-4b3f-8170-3c575069778e"
      },
      "source": [
        "plt.plot(history.history['value_net_accuracy'], label='V_accuracy')\n",
        "plt.plot(history.history['val_value_net_accuracy'], label = 'V_val_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([0.5, 1])\n",
        "plt.legend(loc='lower right')\n",
        "\n",
        "plt.plot(history.history['policy_net_accuracy'], label='P_accuracy')\n",
        "plt.plot(history.history['val_policy_net_accuracy'], label = 'P_val_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([0.5, 1])\n",
        "plt.legend(loc='lower right')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f800a11fa50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58VjdikZPjU3"
      },
      "source": [
        "Op2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "FRM_EkqZNyxd",
        "outputId": "e1e9b4fa-d414-4e6c-b306-5fb3d904696b"
      },
      "source": [
        "plt.plot(history.history['value_net_loss'], label='V_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.ylim([0.5, 1])\n",
        "plt.legend(loc='lower right')\n",
        "\n",
        "plt.plot(history.history['policy_net_loss'], label='P_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.ylim([0.5, 1])\n",
        "plt.legend(loc='lower right')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f80095d22d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "id": "0LvwaKhtUdOo",
        "outputId": "3aaf6e27-8577-4d35-dafe-6d614cd47fe7"
      },
      "source": [
        "test_loss, test_acc = model.evaluate(arrtr,  arr2tr, verbose=2)\n",
        "print(test_acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-49497eab5e45>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrtr\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0marr2tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'arrtr' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t8L7I4OyHSd2"
      },
      "source": [
        "**Save Model - Necessita Google Drive para exportação **"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QwQVqHHRC27f"
      },
      "source": [
        "**Save Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PXocJPUFBb-x",
        "outputId": "9f60f40b-1264-4a0d-f9d9-bf49032ad87e"
      },
      "source": [
        "saved_model_path = \"dotsandboxes3b\"\n",
        "tf.keras.models.save_model(model, saved_model_path)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: dotsandboxes3b/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKUAHnOVHTai"
      },
      "source": [
        "model.save(\"dotsandboxes3.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WmLJcYyXhG0n"
      },
      "source": [
        "**Input e Output**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6dUk-gi4Qd0"
      },
      "source": [
        "saved_model_path = \"dotsandboxes3_41\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BdDwYWKGOMhI",
        "outputId": "26a57a41-d7c6-4512-8f97-f4b58acf91b5"
      },
      "source": [
        "loaded = tf.keras.models.load_model(saved_model_path)\n",
        "print(list(loaded.signatures.keys()))  # [\"serving_default\"]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['serving_default']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "id": "AgcWZFVy4k8d",
        "outputId": "0d018605-214c-4e41-8814-533fd2443bf2"
      },
      "source": [
        "#history = loaded.fit(x=arrtr, y=[arr2tr, arr3tr], batch_size=64, epochs=10, validation_data=(arrtest, [arr2test, arr3test]))\n",
        "history = loaded.fit(x=gamestr, y=[policytr, valuestr], batch_size=64, epochs=100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-5f209fa48e5f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#history = loaded.fit(x=arrtr, y=[arr2tr, arr3tr], batch_size=64, epochs=10, validation_data=(arrtest, [arr2test, arr3test]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloaded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgamestr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpolicytr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvaluestr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'loaded' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zaAk4PVh4CdZ",
        "outputId": "0ff67522-69a3-4cec-8b62-e12f1243755a"
      },
      "source": [
        "saved_model_path = \"dotsandboxes3_42\"\n",
        "tf.keras.models.save_model(loaded, saved_model_path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: dotsandboxes3_42/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M65DrVrYaj9-"
      },
      "source": [
        "import pandas as pd\n",
        "hist_df = pd.DataFrame(history.history) \n",
        "hist_json_file = f\"Results/history-1t.json\" \n",
        "with open(hist_json_file, mode='w') as f1:\n",
        "    hist_df.to_json(f1)\n",
        "# save to csv:  \n",
        "hist_csv_file = f\"Results/history-1t.csv\"\n",
        "with open(hist_csv_file, mode='w') as f2:\n",
        "    hist_df.to_csv(f2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "faIw1tYJOn0a",
        "outputId": "bb9f41b7-0bad-40ed-df57-16ef566078ee"
      },
      "source": [
        "infer = loaded.signatures[\"serving_default\"]\n",
        "print(infer.structured_outputs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'policy_net': TensorSpec(shape=(None, 28), dtype=tf.float32, name='policy_net'), 'value_net': TensorSpec(shape=(None, 1), dtype=tf.float32, name='value_net')}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pb-Maxi3hP0Y",
        "outputId": "9eafa65e-daa7-455a-d1b1-a4872a35571d"
      },
      "source": [
        "input_tensor = model.inputs[0]\n",
        "output_tensor = model.outputs[0]\n",
        "output_tensor1 = model.outputs[1]\n",
        "print(\"Inputs: \"+str(input_tensor))\n",
        "print(\"Outputs: \"+str(output_tensor))\n",
        "print(\"Outputs: \"+str(output_tensor1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Inputs: KerasTensor(type_spec=TensorSpec(shape=(None, 7, 4), dtype=tf.float32, name='state_7_4'), name='state_7_4', description=\"created by layer 'state_7_4'\")\n",
            "Outputs: KerasTensor(type_spec=TensorSpec(shape=(None, 28), dtype=tf.float32, name=None), name='policy_net/Softmax:0', description=\"created by layer 'policy_net'\")\n",
            "Outputs: KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='value_net/Tanh:0', description=\"created by layer 'value_net'\")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tl5bVWrFtvzL"
      },
      "source": [
        "# Prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CvSB4OTdHbNK"
      },
      "source": [
        "Test prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wy6OqhXBHeJv"
      },
      "source": [
        "pred = np.loadtxt(predict, dtype=float)\n",
        "pred = pred.reshape(24, 7, 4)\n",
        "r, v = model.predict(pred)\n",
        "print(r)\n",
        "print(v)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmdWxEN5HfdC"
      },
      "source": [
        "Default prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVm8ntc9tw94"
      },
      "source": [
        "pred = np.loadtxt(predictPath, dtype=float)\n",
        "pred = pred.reshape(35, 10, 7, 4)\n",
        "# binary classification\n",
        "result = np.where(model.predict(pred) > .5, 1,0)\n",
        "print(result)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "njvpkNGHLAU9"
      },
      "source": [
        "Prediction from game"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mw8HjT2QLAFq"
      },
      "source": [
        "pr = np.array([[[[0, 1, 1, 0],[1, 1, 1, 1],[0, 1, 1, 0],[1, 0, 0, 1],[0, 0, 0, 0],[1, 1, 0, 1],[1, 1, 1, 0]],[[0, 1, 1, 0],[1, 1, 1, 1],[0, 1, 1, 0],[1, 0, 0, 1],[1, 0, 0, 0],[1, 1, 0, 1],[1, 1, 1, 0]],[[0, 1, 1, 0],[1, 1, 1, 1],[0, 1, 1, 0],[1, 0, 0, 1],[1, 1, 0, 0],[1, 1, 0, 1],[1, 1, 1, 0]],[[1, 1, 1, 0],[1, 1, 1, 1],[0, 1, 1, 0],[1, 0, 0, 1],[1, 1, 0, 0],[1, 1, 0, 1],[1, 1, 1, 0]],[[1, 1, 1, 0],[1, 1, 1, 1],[0, 1, 1, 0],[1, 0, 0, 1],[1, 1, 0, 0],[1, 1, 1, 1],[1, 1, 1, 0]],[[1, 1, 1, 0],[1, 1, 1, 1],[0, 1, 1, 0],[1, 0, 0, 1],[1, 1, 0, 0],[1, 1, 1, 1],[1, 1, 1, 0]],[[1, 1, 1, 0],[1, 1, 1, 1],[0, 1, 1, 0],[1, 0, 0, 1],[1, 1, 0, 0],[1, 1, 1, 1],[1, 1, 1, 0]],[[1, 1, 1, 0],[1, 1, 1, 1],[0, 1, 1, 0],[1, 0, 0, 1],[1, 1, 1, 0],[1, 1, 1, 1],[1, 1, 1, 0]],[[1, 1, 1, 0],[1, 1, 1, 1],[1, 1, 1, 0],[1, 0, 0, 1],[1, 1, 1, 0],[1, 1, 1, 1],[1, 1, 1, 0]],[[1, 1, 1, 0],[1, 1, 1, 1],[1, 1, 1, 0],[1, 1, 0, 1],[1, 1, 1, 0],[1, 1, 1, 1],[1, 1, 1, 0]]]])\n",
        "result = np.where(model.predict(pr) > .5, 1,0)\n",
        "print(result)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}